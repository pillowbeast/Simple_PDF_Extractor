{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eced1c2d",
   "metadata": {},
   "source": [
    "# PDFDataExtractor Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ebc98f",
   "metadata": {},
   "source": [
    "PDFDataExtractor is a toolkit for automatically extracting semantic information from PDF files of scientific articles, which features a template-based architecture with abilities to extract information from the following various publishers: \n",
    "* Elsevier\n",
    "* Royal Society of Chemistry\n",
    "* Advanced Material Families (Wiley)\n",
    "* Angewandte\n",
    "* Chemistry A European Journal\n",
    "* American Chemistry Society\n",
    "* Springer (Temporarily unavailable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3103dc4e",
   "metadata": {},
   "source": [
    "## To install PDFDataExtractor, simply run the following code in your terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d20cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "git clone git@github.com:cat-lemonade/PDFDataExtractor.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde0a77",
   "metadata": {},
   "source": [
    "## Then run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35f76b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1000827859.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\yanni\\AppData\\Local\\Temp\\ipykernel_6988\\1000827859.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python setup.py install\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python setup.py install"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9b5039",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf90c1ac",
   "metadata": {},
   "source": [
    "## Pass a single PDF file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8db3a07",
   "metadata": {},
   "source": [
    "### Import necessary module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a636447e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pdfdataextractor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6988\\899850781.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpdfdataextractor\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pdfdataextractor'"
     ]
    }
   ],
   "source": [
    "from pdfdataextractor import Reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5beed496",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r'../data/acs.jcim.6b00207.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d1b8407",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89095cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading:  /Users/miao/Downloads/acs.jcim.6b00207.pdf\n",
      "*** American Chemistry Society detected ***\n"
     ]
    }
   ],
   "source": [
    "pdf = file.read_file(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423d2bed",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6526f55c",
   "metadata": {},
   "source": [
    "### Test if PDF is returned successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae45c0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF returned successfully\n"
     ]
    }
   ],
   "source": [
    "pdf.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52fb8b9c",
   "metadata": {},
   "source": [
    "### Get Caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2aece6b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'figure 1': 'Figure 1. Overview of the complete information extraction system. Document Processors convert various input formats into a universal document model that consists of a single linear stream of elements such as paragraphs and tables that are each processed independently to extract information. This information is then merged to produce a single collection of chemical records for the overall document.',\n",
       " 'figure 2': 'Figure 2. Natural language processing pipeline. Text is ﬁrst split into sentences and then into individual tokens. The part-of-speech tagger and entity recognizer outputs are combined to assign a single tag to each token, which is then parsed using a rule-based grammar to produce a tree structure. This tree structure is interpreted to extract individual chemical records for this sentence, which are then combined to resolve data with records interdependencies and produce uniﬁed records for depositing in a database. Tags shown: NN = noun, CD = cardinal number, VBZ = verb (third person singular present), DT = determiner, NNS = noun plural, JJ = adjective, CC = coordinating IN = preposition, conjunction, CM = chemical mention.',\n",
       " 'figure 3': 'Figure 3. Supervised (solid lines) and unsupervised (dashed lines) training methods for machine learning-based NLP components. The sentence tokenizer relies entirely on unsupervised training using the raw text of chemistry articles, whereas the part-of-speech tagger and chemical entity recognizer combine unsupervised features from word clusters with supervised training from labeled corpora, such as GENIA (2000 MEDLINE abstracts with manually annotated part-of-speech tags) and CHEMDNER (10 000 PubMed abstracts with manually annotated chemical entity mentions).',\n",
       " 'figure 4': 'Figure 4. Most common words in seven example word clusters. The binary path deﬁnes the hierarchical position for each cluster. Larger cluster supersets can be obtained by considering diﬀerent length preﬁxes of the binary path.',\n",
       " 'figure 5': 'Figure 5. Example rule-based parsing grammar chemical names with an associated alphanumeric label.',\n",
       " 'figure 6': 'Figure 6 shows an example of a simple table that contains a UV−vis absorption peak wavelength and extinction value for a single compound. After each cell has been separately tokenized and tagged, the heading cells are parsed to determine the column types and units. In this case, the ﬁrst column contains chemical entity identiﬁers, and the second column contains combined UV−vis wavelength and extinction values. Each subsequent row is then processed individually to produce a chemical record, taking into account the column classiﬁcation from each heading to choose the appropriate parsing grammar for the cells below.',\n",
       " 'figure 7': 'Figure 7. Example of how information from sentences, captions, and tables is combined to produce a structured data record.',\n",
       " 'figure 8': 'Figure 8. Data model for extracted chemical entities and their associated experimental properties and spectroscopic attributes, as currently provided by ChemDataExtractor. Users of the toolkit may extend this data model by deﬁning their own custom parsers.',\n",
       " 'figure 9': 'Figure 9. Data distributions of melting point temperature values extracted by ChemDataExtractor (blue) and Tetko (green) from the evaluation sample of 2000 patents. The distribution for the entire Tetko data set of 241 958 melting points is also shown in red. Note that duplicate removal was performed on the entire Tetko data set, prior to the evaluation sample being taken.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.caption()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2040fc4",
   "metadata": {},
   "source": [
    "### Get Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8b33d4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.keywords()# Note: Some articles do not contain keywords. For example, the current one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e1ab0",
   "metadata": {},
   "source": [
    "### Get Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a66f3899",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ChemDataExtractor: A Toolkit for Automated Extraction of Chemical Information from the Scientiﬁc Literature'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.title()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b42a22",
   "metadata": {},
   "source": [
    "### Get DOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d560ebe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10.1021/acs.jcim.6b00207'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.doi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72a45de5",
   "metadata": {},
   "source": [
    "### Get Abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79f95f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABSTRACT: The emergence of “big data” initiatives has led to the need for tools that can automatically extract valuable chemical information from large volumes of unstructured data, such as the scientiﬁc literature. Since chemical information can be present in ﬁgures, tables, and textual paragraphs, successful information extraction often depends on the ability to interpret all of these domains simultaneously. We present a complete toolkit for the automated extraction of chemical entities and their associated properties, measurements, and relationships from scientiﬁc documents that can be used to populate structured chemical databases. Our system provides an extensible, chemistry-aware, natural language processing pipeline for tokenization, part-of-speech tagging, named entity recognition, and phrase parsing. Within this scope, we report improved performance for chemical named entity recognition through the use of unsupervised word clustering based on a massive corpus of chemistry articles. For phrase parsing and information extraction, we present the novel use of multiple rule-based grammars that are tailored for interpreting speciﬁc document domains such as textual paragraphs, captions, and tables. We also describe document-level processing to resolve data interdependencies and show that this is particularly necessary for the autogeneration of chemical databases since captions and tables commonly contain chemical identiﬁers and references that are deﬁned elsewhere in the text. The performance of the toolkit to correctly extract various types of data was evaluated, aﬀording an F-score of 93.4%, 86.8%, and 91.5% for extracting chemical identiﬁers, spectroscopic attributes, and chemical property attributes, respectively; set against the CHEMDNER chemical name extraction challenge, ChemDataExtractor yields a competitive F-score of 87.8%. All tools have been released under the MIT license and are available to download from http://www.chemdataextractor.org.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.abstract()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c4e5f",
   "metadata": {},
   "source": [
    "### Get Journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b5d4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       " 'year': '2016',\n",
       " 'volume': '56',\n",
       " 'page': '1894-1904'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.journal()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698dbdb1",
   "metadata": {},
   "source": [
    "### Get Journal name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e367a992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'J. Chem. Inf. Model. 2016, 56, 1894−1904'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.journal('name')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0bd54",
   "metadata": {},
   "source": [
    "### Get Journal Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8843ea2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2016'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.journal('year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08318496",
   "metadata": {},
   "source": [
    "### Get Journal Volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8f11940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'56'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.journal('volume')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d8fdf9",
   "metadata": {},
   "source": [
    "### Get Journal Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a55d26c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1894-1904'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.journal('page')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3e3289",
   "metadata": {},
   "source": [
    "### Get Plain Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e8ce1538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Article\\n\\npubs.acs.org/jcim\\n\\nChemDataExtractor: A Toolkit for Automated Extraction of Chemical\\nInformation from the Scientiﬁc Literature\\nMatthew C. Swain and Jacqueline M. Cole*\\n\\nCavendish Laboratory, University of Cambridge, J. J. Thomson Avenue, Cambridge, CB3 0HE, U.K.\\n\\nABSTRACT: The emergence of “big data” initiatives has led\\nto the need for tools that can automatically extract valuable\\nchemical information from large volumes of unstructured data,\\nsuch as the scientiﬁc literature. Since chemical information can\\nbe present in ﬁgures, tables, and textual paragraphs, successful\\ninformation extraction often depends on the ability to interpret\\nall of these domains simultaneously. We present a complete\\ntoolkit for the automated extraction of chemical entities and\\ntheir associated properties, measurements, and relationships\\nfrom scientiﬁc documents that can be used to populate\\nstructured chemical databases. Our system provides an extensible, chemistry-aware, natural language processing pipeline for\\ntokenization, part-of-speech tagging, named entity recognition, and phrase parsing. Within this scope, we report improved\\nperformance for chemical named entity recognition through the use of unsupervised word clustering based on a massive corpus\\nof chemistry articles. For phrase parsing and information extraction, we present the novel use of multiple rule-based grammars\\nthat are tailored for interpreting speciﬁc document domains such as textual paragraphs, captions, and tables. We also describe\\ndocument-level processing to resolve data interdependencies and show that this is particularly necessary for the autogeneration of\\nchemical databases since captions and tables commonly contain chemical identiﬁers and references that are deﬁned elsewhere in\\nthe text. The performance of the toolkit to correctly extract various types of data was evaluated, aﬀording an F-score of 93.4%,\\n86.8%, and 91.5% for extracting chemical identiﬁers, spectroscopic attributes, and chemical property attributes, respectively; set\\nagainst the CHEMDNER chemical name extraction challenge, ChemDataExtractor yields a competitive F-score of 87.8%. All\\ntools have been released under the MIT license and are available to download from http://www.chemdataextractor.org.\\n\\n■ INTRODUCTION\\n\\nScientiﬁc results are typically communicated in the form of\\npapers, patents, and theses that contain unstructured and\\nsemistructured data described by free-ﬂowing natural language\\nthat is not readily interpretable by machines. Yet, manual data\\nabstraction by humans with expert knowledge is an expensive,\\nlabor-intensive, and error-prone process. With the continued\\ngrowth of new publications, it is becoming increasingly diﬃcult\\nto create and maintain up-to-date manually curated databases,\\nand automated information extraction by machines is fast\\nbecoming a necessity.\\n\\nThe chemistry literature presents an attractive and tractable\\ntarget for this automated extraction as it is typically comprised\\nof formulaic, data-rich language that is well-suited for machine\\nanalysis with the potential for high recall and precision. The\\nextracted chemical\\ninformation can be used to create and\\npopulate databases of chemical structures, properties, and\\nobservations, opening up new avenues for discovery through\\nlarge-scale data mining studies that are of great value in diverse\\nareas\\nsuch as materials discovery, drug discovery, and\\nintellectual property protection.\\n\\nIn recent years, eﬀorts such as The Materials Genome\\nInitiative1 have led to an increased focus on large-scale data-\\nmining for materials discovery. Notable projects include the\\nHarvard Clean Energy Project,2 which focuses on materials for\\norganic photovoltaics, and the Materials Project,3 which focuses\\n\\non battery materials. These existing projects are primarily\\nconﬁned to exploiting computational\\nresources to predict\\nchemical properties, an approach that would be well\\ncomplemented by wider availability of machine-readable\\ndatabases of experimental properties. Moreover, a generic\\nmethod that can automatically generate a database for any type\\nof material property would extend the reach of existing eﬀorts\\nto all areas of materials science, rather than predeﬁning a focus\\non a speciﬁc area.\\n\\nWhile there are many well-established text-mining tools in\\nthe biomedical domain,4−7 chemistry and materials text-mining\\nis less widespread and fewer tools have been developed.\\nReviews by Eltyeb and Salim,8 Vazquez et al.,9 and Guru-\\nlingappa et al.10 provide comprehensive overviews of\\nthe\\nexisting chemistry text-mining tools and methods. Most of\\nthese tools focus narrowly on extracting speciﬁc entity types\\nfrom speciﬁc document domains, while there are relatively few\\nmethodologies that embrace a broader focus on the extraction\\nof chemical\\nincluding properties, experimental\\nmeasurements, and relationships between entities.\\n\\ninformation,\\n\\nOne such tool\\n\\nis ChemicalTagger,11 which parses exper-\\nimental synthesis sections of documents to determine chemical\\nroles (e.g., reactant, solvent) and relationships with exper-\\n\\nReceived: April 13, 2016\\nPublished: September 26, 2016\\n\\n© 2016 American Chemical Society\\n\\n1894\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nFigure 1. Overview of the complete information extraction system. Document Processors convert various input formats into a universal document\\nmodel that consists of a single linear stream of elements such as paragraphs and tables that are each processed independently to extract information.\\nThis information is then merged to produce a single collection of chemical records for the overall document.\\n\\nimental actions (e.g., heated, stirred), through the use of an\\nANTLR grammar12 for rule-based text parsing and OSCAR13\\nfor chemical named entity recognition. ChemicalTagger has\\nbeen used in conjunction with the commercial tool LeadMine14\\nthe extraction of melting points from patents,15 and\\nfor\\nadditionally, the ChemEx project16 extended ChemicalTagger\\nwith additional biomedical entity recognizers and image\\nrecognition of 2D chemical structures using OSRA.17\\n\\nin particular, highlight\\n\\nGurulingappa et al.10 outline the various challenges to further\\nprogress, and,\\nthe distribution of\\ninformation across diﬀerent components of documents, such\\nas textual paragraphs, images, tables, and captions, as one of the\\nprimary barriers to successful extraction of chemical informa-\\ntion.\\n\\nIn this paper, we present a comprehensive toolkit for the\\nautomated extraction of chemical information from scientiﬁc\\ndocuments. The toolkit provides a complete natural language\\nprocessing (NLP) pipeline that makes use of a wide range of\\nstate-of-the-art methods, including a chemistry-aware part-of-\\nspeech (POS) tagger, named entity recognizers that combine\\nconditional random ﬁelds and dictionaries, rule-based gram-\\nmars for phrase parsing, and word clustering to improve\\nperformance of machine learning methods through unsuper-\\nvised training. In addition, the toolkit includes a table parser for\\nextracting information from semistructured tabulated data, and\\ndocument-level postprocessing algorithms to resolve data\\ninterdependencies between information extracted from diﬀer-\\nent parts of a document.\\n\\nBy automating the extraction of chemical entities, properties,\\nmeasurements, and procedures, our\\ntoolkit enables vast\\nchemical databases to be created and populated with minimal\\ntime, eﬀort, and expense.\\n\\n■ IMPLEMENTATION\\n\\nSystem Overview. Our system provides an end-to-end\\ntext-mining pipeline that takes PDF, HTML, and XML ﬁles as\\ninput and produces an output of machine-readable structured\\ndata that is suitable for depositing in a database. Figure 1\\npresents an overview of the system. Our approach to each stage\\nof the process is described below.\\n\\nDocument Processing. The ﬁrst stage of the system is to\\nprocess PDF, HTML, and XML ﬁles to isolate the relevant\\ndocument domains, extract the raw text, and merge potentially\\nfragmented data from diﬀerent sources to produce a complete\\ndocument record. The end result is a consistent, simpliﬁed\\ndocument structure that consists of a single linear stream of\\ntitle, abstract, heading, paragraph, ﬁgure, and table document\\nelements. This allows subsequent components in the pipeline\\n\\nto process each document in exactly the same way, regardless of\\nthe original document format.\\n\\nFor text from HTML and XML sources, semantic markup of\\nheadings, paragraphs, captions and tables makes processing a\\ntrivial process. Once each text domain has been isolated, any\\nfurther embedded markup (for example specifying bold and\\nitalic characters) is stripped to produce plain text for natural\\nlanguage processing. For tables, individual cells are treated as\\nseparate text domains, and stored in nested lists that represent\\nthe original table structure.\\n\\nPDF documents present a greater challenge, as the format is\\nnot designed for the content to be easily interpreted by a\\nmachine. ChemDataExtractor provides layout analysis tools,\\nbuilt on top of the PDFMiner framework,18 that use the\\npositions of\\nimages and text characters to group text into\\nheadings, paragraphs, and captions.\\n\\nNatural Language Processing. The natural\\n\\nlanguage\\nprocessing pipeline extracts structured information from the\\nEnglish-language text in headings, paragraphs, and captions. It\\nis made up of ﬁve main stages: tokenization, part-of-speech\\ntagging, named entity recognition, phrase parsing, and\\ninformation extraction. Figure 2 shows an overview of the\\npipeline, alongside an illustration of each stage applied to an\\nexample text passage.\\n\\nTokenization. The tokenization process converts\\n\\ntext\\npassages into a stream of tokens that are suitable for natural\\nlanguage processing. Text is ﬁrst split into sentences, and then\\neach sentence is\\nthat broadly\\nsplit\\nfurther\\ncorrespond to individual words and punctuation.\\n\\ninto tokens\\n\\nOur system provides a sentence splitter that makes use of the\\nPunkt algorithm by Kiss and Strunk,19 which detects sentence\\nboundaries\\nthrough unsupervised learning of common\\nabbreviations and sentence starters. This algorithm has been\\nshown to be broadly applicable to many languages and text\\ndomains, and performs best when it has been trained on text\\nfrom the target domain.20 The unsupervised nature of this\\ntraining process makes this method particularly well-suited to\\nthe chemistry domain, where there is a huge archive of\\nliterature available, and yet, very few collections have been\\nmanually annotated with features such as sentence boundaries.\\nOur sentence splitter has been trained on the abstract, main\\ntext and captions of 3592 chemistry articles published by The\\nAmerican Chemical Society (ACS), The Royal Society of\\nChemistry (RSC), and Springer. The sentence splitter identiﬁes\\n702 132 individual sentences in the training articles, correctly\\ndistinguishing true sentence boundaries from full stops that\\noccur in abbreviations, such as “et al.”, “ﬁg.”, “ref.”, and “equiv.”\\nthat are prevalent in the chemistry literature.\\n\\n1895\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nproviding a large collection of text from the target domain that\\nhas been manually annotated with the desired results. However,\\nprevious work has shown that\\nthese\\nmethods can be improved by adding unsupervised word\\nrepresentations as extra word features.21 This is particularly\\nuseful\\nin the chemistry domain, where the relative lack of\\nannotated text collections for supervised training can be\\ncompensated for by using word cluster features derived from\\nthe extensive and widely available unannotated literature.\\n\\nthe performance of\\n\\nOur system makes use of\\n\\nfeatures derived from Brown\\nclustering,22 a form of hierarchical clustering of words based on\\nthe contexts in which they occur. This has been shown to\\nimprove the performance of part-of-speech tagging and named\\nentity recognition in a variety of domains.21,23−26 Figure 3\\nshows how various components of our natural\\nlanguage\\nprocessing pipeline incorporate both unsupervised and\\nsupervised learning.\\n\\nFigure 2. Natural language processing pipeline. Text is ﬁrst split into\\nsentences and then into individual tokens. The part-of-speech tagger\\nand entity recognizer outputs are combined to assign a single tag to\\neach token, which is then parsed using a rule-based grammar to\\nproduce a tree structure. This tree structure is interpreted to extract\\nindividual chemical records for this sentence, which are then combined\\nto resolve data\\nwith records\\ninterdependencies and produce uniﬁed records for depositing in a\\ndatabase. Tags shown: NN = noun, CD = cardinal number, VBZ =\\nverb (third person singular present), DT = determiner, NNS = noun\\nplural,\\nJJ = adjective, CC = coordinating\\nIN = preposition,\\nconjunction, CM = chemical mention.\\n\\nfrom throughout\\n\\nthe document\\n\\nThe word tokenizer has been designed to broadly match the\\nPenn Treebank policy, with some modiﬁcations to better\\nhandle chemistry text. Tokens are split on all whitespace and\\nmost punctuation characters, with exceptions for brackets,\\ncolons, and other symbols in certain situations to preserve\\nentities such as chemical names as a single token. Additionally,\\ncare is taken to consistently split units and mathematical\\nsymbols from numeric values, regardless of whether the source\\ntext contains a space between them.\\n\\nsystems\\n\\nto other\\n\\nthat normalize text prior\\n\\nText normalization is an important step that\\n\\nremoves\\ncommonly occurring inconsistencies that have a detrimental\\nimpact on the performance of machine learning and dictionary\\nmethods, and add unnecessary complexity to parsing rules. In\\ncontrast\\nto\\ntokenization, our tokenizer is designed to operate on any\\nsubsequently\\ninput, and normalization is\\nunicode text\\nperformed on the text content of each individual token. The\\nadvantage of this approach is that each token can retain a\\npointer to its exact start and end position within the source text,\\neven if normalization then changes the length of\\ntokens.\\nTherefore, the original token text can always be recovered, and\\nany information derived about a token can be easily annotated\\nback onto the original document.\\n\\nAs part of the normalization, unicode characters with similar\\nappearance that are often used interchangeably are stand-\\nardized, all nonprinting control characters are removed, and\\nalternative chemical spellings are uniﬁed.\\n\\nWord Clustering. To achieve good performance, many\\nmachine learning techniques that are used in natural language\\nprocessing must ﬁrst be trained in a supervised fashion by\\n\\nFigure 3. Supervised (solid lines) and unsupervised (dashed lines)\\ntraining methods for machine learning-based NLP components. The\\nsentence tokenizer relies entirely on unsupervised training using the\\nraw text of chemistry articles, whereas the part-of-speech tagger and\\nchemical entity recognizer combine unsupervised features from word\\nclusters with supervised training from labeled corpora, such as GENIA\\n(2000 MEDLINE abstracts with manually annotated part-of-speech\\ntags) and CHEMDNER (10 000 PubMed abstracts with manually\\nannotated chemical entity mentions).\\n\\nClustering was performed on the full text and captions of\\n3592 chemistry articles published by the ACS, RSC, and\\nSpringer. Once tokenized, this collection consists of about 20\\nmillion words in about 700 000 sentences. Clustering was\\nperformed using the Liang C++ implementation27 to produce\\n1500 clusters containing 372 799 unique words. Figure 4 shows\\nthe highest frequency words in seven example clusters. As\\nBrown clusters are hierarchical, diﬀerent length preﬁxes of the\\nbinary path correspond to cluster supersets, which can also be\\nused as features in machine learning methods.\\n\\nPart-of-Speech-Tagging. Part-of-speech (POS) tagging\\ninvolves assigning a tag to each token that describes its\\nsyntactic function, for example as a noun, verb or adjective.\\nEntity recognition, phrase parsing, and information extraction\\ntools routinely use the POS tags on tokens as part of their\\ninput, and thus their success is often highly dependent on the\\naccuracy of the tagging process.\\n\\nThe vast majority of publicly available natural\\n\\nlanguage\\nprocessing tools provide POS taggers that have been trained on\\nnewspaper articles, and therefore do not necessarily perform\\nwell on chemistry literature. Tsuruoka et al.4 found that by\\ntraining a POS tagger on a combined corpus of newspaper\\narticles (WSJ corpus28) and MEDLINE abstracts (GENIA\\ncorpus29), performance in the biomedical domain was greatly\\n\\n1896\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nFigure 4. Most common words in seven example word clusters. The binary path deﬁnes the hierarchical position for each cluster. Larger cluster\\nsupersets can be obtained by considering diﬀerent length preﬁxes of the binary path.\\n\\nimproved. In the absence of any equivalent POS-annotated\\ncorpus that covers the wider chemistry domain, the POS tagger\\nin our system makes use of the same newspaper and biomedical\\ntraining corpora but also supplements these with unsupervised\\nword cluster features derived from chemistry articles. This\\nimproves performance across a wider range of subject areas and\\ndocument domains (such as captions) that are not well-covered\\nby the training corpora.\\n\\nThe POS tagger uses a linear-chain conditional random ﬁeld\\n(CRF) model, trained using the orthant-wise limited-memory\\nquasi-Newton (OWL-QN) method as implemented by the\\nCRFsuite framework.30 The features for each token are shown\\nin Table 1. The word shape feature is derived by replacing every\\n\\nTable 1. Features Used in the POS Tagger\\n\\na\\n\\nfeature\\n\\ncontext\\n\\ndescription\\n\\nwi−2, wi−1, wi, wi+1, wi+2\\nwi−2wi−1, wi−1wi, wiwi+1,\\n\\nwi+1wi+2\\n\\nwi−2, wi−1, wi, wi+1, wi+2\\nwi−2, wi−1, wi, wi+1, wi+2\\n\\nword\\nbigrams\\n\\nword shape\\nBrown\\n\\nclusters\\n\\nlength\\npreﬁxes\\nsuﬃxes\\nhyphenated\\nalphabetical\\n\\ncase\\nnumber\\npunctuation\\n\\nwi\\nwi\\nwi\\nwi\\nwi\\n\\nwi\\nwi\\nwi\\n\\nnormalized lowercase token text\\ncombinations of consecutive\\n\\nsimpliﬁed token representation\\n4, 6, 10, and 20 bit binary path\\n\\ntokens\\n\\npreﬁxes\\n\\nnumber of characters in token\\n1−5 character preﬁxes\\n1−5 character suﬃxes\\ncontains a hyphen character\\ncontains only alphabetical\\n\\ncharacters\\n\\nupper, lower, or title cased\\nnumber in digit or word form\\ncontains only punctuation\\n\\ncharacters\\n\\naA context window is used, such that some features for the token at\\nindex i are derived from the token text (w) of surrounding tokens.\\n\\nnumber with “d”, every greek letter with “g”, and every latin\\nletter with “X” or “x” for uppercase and lowercase, respectively.\\nChemical Named Entity Recognition. In order to extract\\ninformation such as relations and properties, the named entities\\ninvolved must ﬁrst be recognized. The task of recognizing\\nchemical entity mentions in text is an area that has recently\\nreceived signiﬁcant attention. The best performing approaches\\ntypically involve a hybrid approach that combines dictionary\\n\\nand rule-based methods with machine learning methods. The\\nOSCAR4 recognizer,13 which uses a maximum-entropy Markov\\nmodel (MEMM), and ChemSpot,31 which uses a CRF model,\\nare two of the most well-established systems. More recently, the\\nCHEMDNER community challenge has promoted the\\ndevelopment of a number of new systems32 and provided the\\nCHEMDNER corpus of 10 000 PubMed abstracts with 84 355\\nmanually annotated chemical entity mentions.33\\n\\nDue to the wide variety of methods with diﬀering strengths,\\nour approach is to provide a modular architecture for named\\nfrom multiple\\nentity recognition that allows the results\\nmethodologies to be combined using heuristic techniques.\\nWe primarily use a CRF-based recognizer for chemical names,\\nin combination with a dictionary-based recognizer that provides\\nimproved performance for trivial and trade names, and a regular\\nexpression-based recognizer that excels for database identiﬁers\\nand chemical formulas.\\n\\nThe dictionary-based recognizer uses a word list compiled\\nfrom the Jochem chemical dictionary34 with an automatic\\nﬁltering process based on the method described by Lowe and\\nSayle14 that excludes entries that lead to false positives. For\\neﬃcient storage and fast string matching, the dictionary is\\nstored as a directed acyclic word graph (DAWG), which uses a\\ngraph-like representation to eliminate redundancy between\\nsimilar names.\\n\\nThe CRF-based recognizer uses a linear-chain CRF model,\\ntrained using the OWL-QN method as implemented by the\\nCRFsuite framework.30 The features that are generated for each\\ntoken are listed in Table 2. An “IOB” labeling scheme was\\nutilized, where each token is labeled as the beginning of a\\nchemical name (B),\\nin a chemical name (I), or outside a\\nchemical name (O). Training was performed using the training\\nsubset of the CHEMDNER corpus and the word clusters\\nderived from chemistry articles.\\n\\nPhrase Parsing. In general, parsing natural\\n\\nlanguage is a\\nchallenging problem, due to ambiguities that mean a single\\nsentence can sometimes be parsed in multiple diﬀerent ways to\\nproduce diﬀerent meanings. In practice, the formulaic and\\nprecise nature of the chemistry literature means that this occurs\\nless often, and parsing to a level that is adequate for information\\nextraction is much more tractable than in other domains.\\n\\nThe ChemicalTagger project pioneered the use of a rule-\\nbased grammar for parsing experimental synthesis sections of\\n\\n1897\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nTable 2. Features Used in CRF Chemical Named Entity\\nRecognizer\\n\\na\\n\\nfeature\\n\\ncontext\\n\\ndescription\\n\\nwi−2, wi−1, wi, wi+1, wi+2\\nword\\nwi−2, wi−1, wi, wi+1, wi+2\\nPOS tags\\nword shape\\nwi−2, wi−1, wi, wi+1, wi+2\\nBrown clusters wi−2, wi−1, wi, wi+1, wi+2\\n\\nnormalized lowercase token text\\npart-of-speech tag\\nsimpliﬁed token representation\\n4, 6, 10, and 20 bit binary path\\n\\nlength\\ncounts\\n\\npreﬁxes\\nsuﬃxes\\nhyphenated\\nalphabetical\\n\\ncase\\nnumber\\npunctuation\\n\\nwi\\nwi\\n\\nwi\\nwi\\nwi\\nwi\\n\\nwi\\nwi\\nwi\\n\\npreﬁxes\\n\\ncounts\\n\\nnumber of characters in token\\ndigit, upper, and lower case letter\\n\\n1−5 character preﬁxes\\n1−5 character suﬃxes\\ncontains a hyphen character\\ncontains only alphabetical\\n\\ncharacters\\n\\nupper, lower, or title cased\\nnumber in digit or word form\\ncontains only punctuation\\n\\ncharacters\\n\\nwi\\n\\nURL\\naA context window is used, such that some features for the token at\\nindex i are derived from the token text (w) of surrounding tokens.\\n\\nlooks like a URL\\n\\nchemistry texts. Their strategy was to attempt to build one\\nuniversal grammar to parse all possible inputs, but this was\\npushing at the practical limits of a single rule-based grammar,\\neven within their relatively narrow target domain.\\n\\nOur alternative strategy is to make use of multiple, more\\nspecialized grammars that are tailored to extracting more\\nspeciﬁc types of chemical\\ninformation. Similarly to Chem-\\nicalTagger, our system produces input for the parser in the\\nform of a merged list of tags from the part-of-speech tagger and\\nchemical entity recognizer. Each grammar consists of a series of\\nnested rules that describe how sequences of tagged tokens can\\nbe translated into a tree model that represents the syntactic\\nstructure of each sentence. Grammars are deﬁned in simple\\nPython code, and unlike other tools, they do not need to be\\ncompiled before use.\\n\\nFigure 5a shows a simpliﬁed grammar, which recognizes\\ndeﬁnitions of alphanumeric compound labels in terms of a full\\nchemical name. The rules are primarily constructed using three\\ncore elements: T, which matches a token based on its POS or\\nentity tag, W, which matches the exact text of a token, and R,\\nwhich matches text patterns using regular expressions. The +\\noperator is used to deﬁne a required sequence of tokens, while\\n\\nFigure 5. Example rule-based parsing grammar\\nchemical names with an associated alphanumeric label.\\n\\nthat\\n\\nrecognizes\\n\\nthe | operator is used where just one of multiple alternatives is\\nrequired. Additional elements such as Optional, Zer-\\noOrMore, and Not allow more complex rules\\nto be\\nconstructed.\\n\\nIn the example grammar shown in Figure 5a, the ﬁrst rule,\\nname, matches a token with the tag B-CM, followed by zero or\\nmore tokens with the tag I-CM, corresponding to the output\\ntags of the chemical named entity recognizer. The second rule,\\nlabel, deﬁnes two regular expression patterns, one for\\nalphanumeric labels and one for Roman numerals, either of\\nwhich may be matched. The ﬁnal rule, cem, is deﬁned in terms\\nof the ﬁrst two rules. It requires a name, followed by a label\\nenclosed within brackets. Figure 5b shows an illustration of the\\ntree data structure that results from applying this grammar to\\nan example sentence.\\n\\nTable Parsing. Tables are a highly attractive target for\\ninformation extraction due to both their high data density and\\nalso their semistructured nature that facilitates interpretation in\\ncomparison to completely unstructured natural\\nlanguage.\\nDespite the lack of strict table format standardization, many\\ntables in the chemistry literature follow broad conventions that\\nmake accurate interpretation possible through rule-based\\nmethods.\\n\\nAn overview of the table parsing system is shown in Figure 6.\\nAt present, ChemDataExtractor primarily targets tables in\\n\\nFigure 6. Overview of the main stages in the table parsing system\\n(left) applied to a simpliﬁed example table (right). First, table headings\\nare parsed to classify the type of each column, and then all the cells in\\neach row are parsed to produce a compound record. The data\\ninterdependency resolution process incorporates information from the\\ntable caption and elsewhere in the document to produce the ﬁnal\\nrecord.\\n\\nwhich each row corresponds to a single chemical entity, and\\neach column describes property values for that entity. By\\ntreating each individual table cell as a short, highly formulaic\\ninformation can be extracted using a specialized\\nsentence,\\nlanguage processing pipeline. This\\nversion of\\nconsists of a more ﬁne-grained tokenizer and a series of rule-\\nbased parsing grammars, each tailored speciﬁcally for extracting\\na certain property type.\\n\\nthe natural\\n\\nColumn headings are parsed ﬁrst, to determine the type of\\ndata in the cells below, as well as any relevant units. Column\\n\\n1898\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nFigure 7. Example of how information from sentences, captions, and tables is combined to produce a structured data record.\\n\\nFigure 8. Data model for extracted chemical entities and their associated experimental properties and spectroscopic attributes, as currently provided\\nby ChemDataExtractor. Users of the toolkit may extend this data model by deﬁning their own custom parsers.\\n\\nheadings can also contain contextual data themselves, such as\\ntemperatures, concentrations or solvent names, which are\\napplied to the property values in every cell below that heading.\\nInterpreting the property values in each cell can be as simple as\\nreading a single numeric value, but multiple bracketed and\\n\\ncomma-separated values within a single cell are commonplace.\\nIn these cases, interpretation of any corresponding bracketed or\\ncomma-separated structure in the column heading is often\\nnecessary to successfully parse the values and assign the correct\\nunits to the correct values.\\n\\n1899\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nFigure 6 shows an example of a simple table that contains a\\nUV−vis absorption peak wavelength and extinction value for a\\nsingle compound. After each cell has been separately tokenized\\nand tagged, the heading cells are parsed to determine the\\ncolumn types and units. In this case, the ﬁrst column contains\\nchemical entity identiﬁers, and the second column contains\\ncombined UV−vis wavelength and extinction values. Each\\nsubsequent row is then processed individually to produce a\\nchemical record, taking into account the column classiﬁcation\\nfrom each heading to choose the appropriate parsing grammar\\nfor the cells below.\\n\\nData Interdependency Resolution. In many cases, the\\ninformation extracted from a single sentence, caption or table\\ncan be meaningless or even misleading without the context\\nprovided by the rest of the document. The ﬁnal stage of our\\nsystem involves postprocessing to resolve these data\\ninterdependencies and combine the data from individual\\ndocument domains into a single complete structured record\\nfor each unique chemical entity that is mentioned in the\\ndocument.\\n\\nChemical Identiﬁer Disambiguation. Initially, each heading,\\nparagraph, caption and table is processed completely\\nindependently to produce structured chemical records that\\nare deﬁned in terms of whatever chemical name, abbreviation,\\nor identiﬁer is used locally in that context. The records from\\nthroughout the document are then combined into a single list,\\nand records that refer to the same chemical entity are merged\\ninto a single record (Figure 7).\\n\\nOur system detects deﬁnitions of chemical abbreviations and\\nlabels using a method based on the algorithm by Hearst and\\nSchwartz.35 This algorithm is applied to all sentences in the\\ndocument to produce a list of mappings between abbreviations\\nand their corresponding full unabbreviated names. These\\nmappings are then used to merge data that is deﬁned in\\nterms of diﬀerent identiﬁers into single records for each unique\\nchemical entity.\\n\\nGlobal Contextual Information. In some cases, a sentence\\ncontains spectroscopic attributes or property information but is\\nlacking any speciﬁc chemical identiﬁcation information. Often,\\nfor example in experimental sections of a research article, the\\nidentiﬁcation information may be available in the\\nchemical\\npreceding sentence or heading, and if so,\\nthis is used.\\nOtherwise,\\ntypically contain contextual\\ninformation (for example, a temperature, solvent, or apparatus)\\nthat is applicable to all properties or spectra of a certain type. In\\nthese cases, the information is merged into all other records for\\nall spectra or properties of that type and the record itself is\\nremoved.\\n\\nthese sentences\\n\\nFinal Data Model. Figure 8 presents the schema of the ﬁnal\\ndata model. The extracted data are primarily based around\\nchemical entity records that contain all the names, abbrevia-\\ntions and labels that were used in the document to refer to a\\ngiven chemical entity. Each chemical entity record can have\\nmultiple associated spectra and properties, and each spectrum\\ncan also optionally contain information about individual peaks.\\nChemDataExtractor comes with built-in parsers and extractors\\nfor the speciﬁc property and spectrum types shown in Figure 8;\\nhowever, the extensible and modular design of ChemDataEx-\\ntractor means that it is straightforward for users to build\\nadditional parsers and extractors for other property and\\nspectrum types.\\n\\nThe ﬁnal chemical records may be saved directly to a\\ndocument-oriented NoSQL database, or to a relational database\\n\\nthrough the use of an object-relational mapper. Alternatively,\\nthey may be exported to a variety of ﬁle formats including\\nMicrosoft Excel, SDF, CSV, or JSON.\\n\\n■ EVALUATION\\n\\nEvaluation Metrics. For all aspects of\\n\\nthe system,\\nperformance has been evaluated in terms of precision (the\\npercentage of retrieved results that are correct), recall (the\\npercentage of correct results that are retrieved), and F-score\\n(harmonic mean of precision and recall). These are deﬁned as\\n\\nprecision\\n\\n=\\n\\nrecall\\n\\n=\\n\\nTP\\n+\\n\\nFP\\n\\nTP\\n\\nTP\\n+\\n\\nTP\\n\\nFN\\n\\n(1)\\n\\n(2)\\n\\nF score\\n\\n‐\\n\\n= ·\\n2\\n\\nprecision recall\\n\\n·\\n+\\n\\nprecision\\n\\nrecall\\n(3)\\nwhere TP is a true positive that the system correctly identiﬁed,\\nFP is a false positive that the system incorrectly identiﬁed, and\\nFN is a false negative that the system failed to recognize.\\n\\nEvaluation of Information Extraction from Academic\\nJournals. Overall performance was evaluated by applying\\nChemDataExtractor to a test collection of 50 open-access\\nchemistry articles that were selected from journals published by\\nthe ACS, RSC, and Springer. The precision, recall and F-score\\nfor the extraction of various diﬀerent kinds of information were\\ncalculated by comparing ChemDataExtractor’s output with a\\ngold standard output36 that was manually compiled especially\\nfor this evaluation. Strict guidelines were developed to ensure\\nmanual extraction was performed consistently.\\n\\nChemical entities, spectra, and properties were extracted\\nfrom the abstract, main text, tables, and ﬁgure captions. For this\\nevaluation, extraction of melting point, oxidation and reduction\\npotentials, photoluminescence lifetime, and quantum yield\\nproperties was considered, as well as NMR, UV−vis, and IR\\nspectroscopic attributes. The relevant chemical entities were\\nrestricted to those with associated spectra or properties, or with\\nan assigned alphanumeric label. All information that is deﬁned\\nsolely within a scheme or ﬁgure image or a separate Supporting\\nInformation document was considered outside the scope of our\\nsystem and was therefore excluded from the evaluation.\\n\\nTable 3 presents the overall precision, recall, and F-score\\nvalues for the extraction of chemical identiﬁers, spectroscopic\\n\\nTable 3. Precision, Recall, and F-Score Measures for the\\nExtraction of Various Kinds of Information\\n\\nchemical identiﬁer records\\nspectrum records\\nchemical property records\\n\\nprecision\\n\\n94.1%\\n88.3%\\n93.5%\\n\\nrecall\\n\\n92.7%\\n85.4%\\n89.6%\\n\\nF-score\\n\\n93.4%\\n86.8%\\n91.5%\\n\\nattributes, and chemical properties. These evaluation metrics\\nconsider the extraction of an entire data record as an individual\\nunit, as shown by the schema diagram in Figure 8. A record is\\nconsidered a false negative if any part of the record is missing, a\\nfalse positive if any part of the record is incorrect, and a true\\npositive only if it is exactly correct.\\n\\nThe following sections present a more detailed evaluation of\\nthe individual components that make up each of the record\\ntypes in Table 3.\\n\\n1900\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nChemical\\n\\nChemDataExtractor’s ability to extract\\n\\nIdentiﬁers. Table 4 presents an evaluation of\\nthe names and\\n\\nTable 4. Precision, Recall, and F-Score Measures for the\\nExtraction of Chemical Identiﬁers\\n\\nchemical names\\nalphanumeric labels\\nfull chemical identiﬁer records\\n\\nprecision\\n\\n97.4%\\n99.3%\\n94.1%\\n\\nrecall\\n\\n96.3%\\n97.3%\\n92.7%\\n\\nF-score\\n\\n96.8%\\n98.3%\\n93.4%\\n\\nalphanumeric labels of chemical entities in a document. Any\\nidentiﬁer that is present in public chemical databases or is\\nresolvable using IUPAC naming rules is considered a name,\\nwhile all other identiﬁers that are typically only applicable\\nwithin the context of the containing document are considered\\nlabels.\\n\\nChemical name extraction is primarily dependent on the\\nthe underlying chemical named entity\\nperformance of\\nrecognizers, while extraction of\\nlabels depends on their\\nproximity to a recognized chemical name or their presence\\nwithin a table.\\n\\nAn F-score of 93.4% was obtained when considering\\nchemical records as a whole, reﬂecting ChemDataExtractor’s\\nability to identify which names and alphanumeric labels\\ncorrespond to the same chemical entity. Accurately matching\\nalphanumeric labels to the relevant chemical name is a vital\\nprerequisite to successfully extracting any spectra and proper-\\nties that are deﬁned solely in terms of a label.\\n\\nSpectroscopic Attributes. An evaluation of ChemDataEx-\\ntractor’s ability to extract various spectroscopic attributes is\\nshown in Table 5. As well as assessing the extraction of each\\nindividual spectrum attribute, the extraction of overall spectrum\\nrecords is presented.\\n\\nTable 5. Precision, Recall, and F-Score Measures for the\\nExtraction of Spectroscopic Attributes\\n\\nspectrum type\\nchemical subject\\npeak values\\nsolvent\\ntemperature\\napparatus\\nfull spectrum records\\n\\nprecision\\n\\n99.9%\\n93.4%\\n98.6%\\n99.5%\\n100%\\n96.9%\\n88.3%\\n\\nrecall\\n\\n96.7%\\n90.3%\\n95.4%\\n96.7%\\n87.5%\\n91.0%\\n85.4%\\n\\nF-score\\n\\n98.4%\\n91.8%\\n96.9%\\n98.1%\\n93.3%\\n93.8%\\n86.8%\\n\\nPrecision is consistently high across all attributes, and some\\neven have no false positives at all within the test set. This is due\\nto the rule-based nature of the parsers in ChemDataExtractor,\\nwhich are well-suited to the formulaic language and structure of\\nscientiﬁc articles that leave little room for misinterpretation.\\n\\nContextual spectroscopic attributes such as temperature and\\napparatus present the greatest challenge in terms of resolving\\ninterdependencies between information that has been extracted\\nfrom diﬀerent document domains. For example, a spectrum\\nmay have peaks listed in a table, temperature mentioned in a\\nﬁgure caption, and apparatus mentioned in the main text,\\nleading to the slightly lower recall values of 87.5% and 91.0%\\nfor temperature and apparatus, respectively. The ability to\\naccurately match together these disparate pieces of information\\nis a unique strength of ChemDataExtractor, yet also presents\\nthe greatest opportunity for further improvement.\\n\\nChemical Properties. Table 6 presents the precision, recall,\\nand F-score for the extraction of diﬀerent aspects of chemical\\nproperty information, as well as the overall property record.\\n\\nTable 6. Precision, Recall, and F-Score Measures for the\\nExtraction of Chemical Properties\\n\\nproperty value\\nproperty units\\nchemical subject\\nsolvent\\ntemperature\\napparatus\\nfull property records\\n\\nprecision\\n\\n100%\\n100%\\n93.5%\\n100%\\n100%\\n100%\\n93.5%\\n\\nrecall\\n\\n95.9%\\n94.8%\\n89.6%\\n94.4%\\n88.9%\\n87.5%\\n89.6%\\n\\nArticle\\n\\nF-score\\n\\n97.9%\\n97.4%\\n91.5%\\n97.1%\\n94.1%\\n93.3%\\n91.5%\\n\\nErrors in property extraction typically occur where properties\\nare reported in sentences within the main text, rather than in a\\ntable. In these cases, while the value and units are normally\\nissue, complex sentence structures often\\nextracted without\\nresult\\nin a failure to assign a chemical subject. Errors in\\nextraction from tables also occasionally arise from complex\\ntable structures; for example where some table cells are merged\\nacross multiple rows or columns, as this can introduce\\nambiguity around the exact scope of the cell contents.\\n\\nEvaluation of Information Extraction from Patents.\\nThe performance of ChemDataExtractor was also tested against\\npatent documents. To this end, a case study on melting points\\nwas used for the evaluation since it oﬀers a good comparison to\\nthe recent work of Tetko et al.,15 who have generated a data set\\nof 241 958 melting points, which were mined from US patents\\nusing LeadMine14 in combination with a customized version of\\nChemicalTagger.11 A comparative evaluation was performed by\\napplying ChemDataExtractor to a representative subset of the\\npatents used in their study and comparing the extracted melting\\npoint records from the two generated data sets. The subset\\ncomprised a sample of 2000 patents, which were drawn from a\\nrandom selection of US patent grants that were published in\\nthe years 2005−2014 and were present in the melting point\\ndata set published by Tetko et al.\\n\\nIn total, ChemDataExtractor obtained 18 180 unique melting\\npoints while Tetko et al. obtained 13 198 from this sample.\\nThere is an overlap of 8978 melting points that match exactly\\nbetween the two data sets, giving a shared total of 22 400\\nin addition to the 8978\\nunique melting points. Therefore,\\n(40%) that are common to both data sets, there are 9202\\n(41%) that occur only in the ChemDataExtractor data set and\\n4220 (19%) that occur only in the Tetko data set. These\\nnonmatching subsets include a further 202 compounds that are\\npresent in both data sets but with diﬀering melting point values.\\nOf the overall set of 9180 common compounds, 97.8% have\\nidentical melting points, while the remaining melting point\\npairings diﬀer by a root mean squared deviation of 63 °C.\\n\\nWhen interpreting these values, it is important to note that\\nTetko et al. removed duplicate values across their entire data\\nset, prior to the evaluation sample being taken, while the\\nChemDataExtractor duplicate values were only removed by\\nconsidering the evaluation sample itself. The published Tetko\\ndata set only references a single patent for each melting point,\\neven if it was extracted from multiple ones, so many of the\\nmelting point values that appear to be missing from the\\nLeadMine-extracted evaluation sample from 2000 patents were\\nin fact intentionally discarded because they were considered to\\n\\n1901\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nbe a duplicate of a value from another patent outside the\\nsample. Also, 2557 compounds for which melting points appear\\nto have been only extracted by ChemDataExtractor do in fact\\noccur in the overall Tetko data set as extracted from a diﬀerent\\npatent. If the beneﬁt of the doubt is given and all of these cases\\nare assumed to be duplicate removals, 11 535 (51%) of values\\nare common to both tools, 6645 (30%) occur only in the\\nChemDataExtractor data set, and 4220 (19%) occur only in the\\nTetko data set. Tetko et al. also discarded an unspeciﬁed\\nnumber of melting points that failed with descriptor calculation\\nprograms, which may further account for diﬀerences between\\nthe two data sets.\\n\\nDespite these diﬀerences, Table 7 shows that there is good\\nagreement between the data sets in terms of this classiﬁcation\\n\\nTable 7. Total Number of Melting Point Values (count),\\nwith the Corresponding Average Temperature (T), Average\\nMolecular Weight (MW), and Average Number of Non-\\nHydrogen Atoms (NA) of the Compounds Involved in the\\nData Records Extracted by ChemDataExtractor and Tetko et\\nal. for the Evaluation Sample of 2000 Patents\\n\\na\\n\\ndata set\\n\\ncount\\n\\naverage\\nMW\\n\\naverage\\nNA\\n\\nChemDataExtractor\\nTetko\\nTetko (all)\\naValues for the entire Tetko dataset are also shown for comparison.\\n\\n18180\\n13198\\n241958\\n\\n385.5\\n385.1\\n357\\n\\n26.9\\n27.0\\n25.0\\n\\naverage T\\n(°C)\\n166.3\\n164.1\\n159\\n\\naccording to the average melting point temperature, average\\nmolecular weight, and average number of non-hydrogen atoms\\nin the compounds involved. Moreover, Figure 9 shows broad\\nagreement in the distribution of melting point temperatures for\\nthe diﬀerent data sets, including being able to reproduce the\\npeaks at 250 and 300 °C.\\n\\nEvaluation of Natural Language Processing Compo-\\nnents. The performance of each individual component in the\\nlanguage processing pipeline can place an eﬀective\\nnatural\\nupper bound on the ability to accurately extract information.\\nImperfect performance in earlier stages carries through the\\npipeline and can degrade the performance of each subsequent\\n\\nFigure 9. Data distributions of melting point temperature values\\nextracted by ChemDataExtractor (blue) and Tetko (green) from the\\nevaluation sample of 2000 patents. The distribution for the entire\\nTetko data set of 241 958 melting points is also shown in red. Note\\nthat duplicate removal was performed on the entire Tetko data set,\\nprior to the evaluation sample being taken.\\n\\nstage. For example,\\nincorrect POS tags can have a direct\\nnegative impact on both the recognition of chemical entities\\nand the parsing of a sentence. Likewise, missing or incorrectly\\nrecognized chemical entity names can invalidate the extraction\\nof all associated spectroscopic data and properties.\\n\\nTherefore,\\n\\nit is important to quantify the performance of\\neach component to identify the greatest barriers to improved\\nperformance of the overall system.\\n\\nChemical Entity Mentions. To facilitate comparison with\\nother text mining tools, recognition of\\nindividual chemical\\nmentions was evaluated. This evaluation was performed using\\nthe CHEMDNER corpus.33 This consists of 3000 abstracts\\nfrom across the chemistry domain that have been manually\\nannotated with 25 351 chemical entity mentions. Results were\\ncalculated using the bc-evaluate tool provided by the\\nCHEMDNER organizers.\\n\\nTable 8 shows the precision, recall and F-score for the\\nindividual CRF, dictionary and regular expression components\\n\\nTable 8. Precision, Recall, and F-Score of Conditional\\nRandom Field (CRF), Dictionary, and Regular Expression\\nChemical Named Entity Recognizers When Used Separately\\nand in Combination\\n\\nsystem\\n\\nprecision\\n\\nCRF\\ndictionary\\nregular expression\\ncombined system\\n\\n90.5%\\n88.6%\\n89.4%\\n89.1%\\n\\nrecall\\n\\n80.0%\\n70.2%\\n11.0%\\n86.6%\\n\\nF-score\\n\\n84.9%\\n78.3%\\n19.6%\\n87.8%\\n\\nof the chemical entity recognition system, as well as for the\\noverall combined system. The overall combined F-score of\\n87.8% exceeds the scores achieved by all the tools that oﬃcially\\nentered the CHEMDNER chemical names extraction chal-\\nlenge.32 The two best entries were tmChem by Leaman et al.,37\\nwhich achieved an F-score of 87.39%, and a system by Lu et\\nal.,38 which achieved an F-score of 87.11%. Lu et al. have since\\npublished an alternative version of their system that achieved an\\nF-score of 88.06%, which outperforms ChemDataExtractor on\\nthis statistic by 0.3%.\\n\\nThe CRF recognizer with word cluster features is the best\\nperforming individual component, with an F-score of 84.9%.\\nWhile the dictionary recognizer has similar precision to the\\nCRF, it has inferior recall, primarily caused by poor recognition\\nof systematic names and chemical formulas. This weakness is\\ntypical of dictionary-based methods, where each chemical name\\nmust be present in the dictionary for it to be successfully\\nrecognized.\\n\\nThe regular expression recognizer\\n\\nis only designed to\\nrecognize a limited set of chemical identiﬁer patterns, such as\\ndatabase registry numbers and chemical formulas, and therefore\\njust 11.0% when applied on its own.\\nhas poor recall of\\nidentiﬁers can pose the\\nHowever, these types of chemical\\ngreatest diﬃculty for the CRF and dictionary methods, and\\ntherefore the regular expression component still makes a\\nworthwhile contribution to the overall combined system.\\n\\nPOS Tagging. POS tagging performance was evaluated\\ntwo diﬀerent corpora that have been\\nthrough the use of\\nmanually annotated with POS tags: The Wall Street Journal\\n(WSJ) corpus,28 which consists of 1 million words from 1989\\nWall Street Journal news articles, and the GENIA corpus,29\\nwhich consists of 2000 MEDLINE abstracts that cover the\\nbiomedical domain. The standard WSJ splitting convention was\\n\\n1902\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nused, with sections 0−18 for training, 19−21 for development,\\nand 22−24 for evaluation. The ﬁrst 90% of the GENIA corpus\\nwas used for training, and the remaining 10% for evaluation,\\nmatching the split used by Tsuruoka et al.4 in developing a\\nbiomedical POS tagger.\\n\\nTable 9 presents the POS tagging accuracy of diﬀerent\\ntraining conﬁgurations on the WSJ and GENIA evaluation\\n\\nTable 9. POS Tagging Accuracy of Diﬀerent Training\\nSystems Evaluated on the WSJ and GENIA Evaluation\\nCorpora\\n\\ntraining system\\n\\nWSJ\\nWSJ + clusters\\nGENIA\\nGENIA + clusters\\nWSJ + GENIA\\nWSJ + GENIA + clusters\\n\\nWSJ\\n\\n97.19%\\n97.23%\\n78.88%\\n81.19%\\n97.02%\\n97.08%\\n\\nGENIA\\n\\n83.50%\\n84.15%\\n98.53%\\n98.62%\\n98.26%\\n98.34%\\n\\ncorpora. Supervised training was performed using the WSJ and\\nGENIA training corpora individually, and also both combined.\\nThe eﬀect of adding unsupervised features from word clusters\\nwas also evaluated on each of these three conﬁgurations.\\n\\nTaggers trained individually on either the WSJ or the GENIA\\ncorpus achieved the best performance when evaluated on that\\nsame corpus but aﬀorded the poorest performance when\\nevaluated on the opposite corpus. The tagger trained on the\\nWSJ training corpus achieved an accuracy of 97.23% on the\\nWSJ evaluation corpus, which falls to 84.15% on the GENIA\\nevaluation corpus. Likewise, the tagger trained on the GENIA\\ntraining corpus achieved an accuracy of 98.62% on the GENIA\\nevaluation corpus, which falls to 81.19% on the WSJ evaluation\\ncorpus.\\n\\nThe tagger trained on the combined WSJ and GENIA\\ncorpora achieves good accuracy on both evaluation corpora,\\nwith 97.08% on the WSJ evaluation corpus and 98.34% on the\\nGENIA evaluation corpus. This matches the observations of\\nTsuruoka et al., indicating that using the combined newspaper\\nand biomedical training sets extends coverage over both and\\nhas little negative impact compared to the specialized training\\nfor a speciﬁc domain.\\n\\nThe addition of word cluster features has a positive eﬀect in\\nall cases, but this is most signiﬁcant in the cases where there is a\\nmismatch between the training corpus and the evaluation\\ncorpus. The accuracy of the WSJ-trained tagger on the GENIA\\ncorpus rises from 83.50% to 84.15%, and the accuracy of the\\nGENIA-trained tagger on the WSJ corpus rises from 78.88% to\\n81.19%. This suggests that unsupervised word cluster features\\nare capable of broadening the coverage of a POS tagger outside\\nthe domain of its supervised training and, therefore, should lead\\nto improved performance across the wider chemistry domain\\nfor the tagger trained on the combined WSJ and GENIA\\n\\ncorpus.■ CONCLUSIONS\\n\\nChemDataExtractor is able to automatically extract chemical\\ninformation from scientiﬁc documents, facilitating the creation\\nof massive chemical databases with minimal time and eﬀort.\\nThe system consists of a modular document processing\\npipeline with extensible components for natural\\nlanguage\\nprocessing that achieve state-of-the-art performance for POS\\ntagging and chemical named entity recognition.\\n\\nArticle\\n\\nIn contrast to most existing text-mining systems that focus\\non extracting entities from individual sentences, ChemDataEx-\\ntractor provides a table processor for extraction of tabulated\\nexperimental properties and document-level processing algo-\\nrithms to resolve data interdependencies and produce uniﬁed\\nchemical records that incorporate information from multiple\\ndocument domains. Evaluations demonstrate good perform-\\nance in the extraction of chemical entities and their associated\\nexperimental properties and spectroscopic data.\\n\\nThe generic and extensible design of the system means it can\\napplied to the extraction of any chemical properties, measure-\\nments and relationships with minimal additional eﬀort. This\\nleads to the ultimate goal of quickly autogenerating chemical\\nstructure and property databases for materials science and other\\nﬁelds. Future work will\\nfocus on extending the system to\\nfurther property and spectrum types, and improving the\\nperformance of\\nlanguage processing\\ncomponents.\\n\\nindividual natural\\n\\n■ AUTHOR INFORMATION\\n\\nCorresponding Author\\n*E-mail: jmc61@cam.ac.uk.\\nNotes\\nThe authors declare no competing ﬁnancial interest.\\nChemDataExtractor is released under the MIT license and is\\navailable to download from http://chemdataextractor.org. An\\ninteractive on line d emo is\\nat h ttp ://\\nchemdataextractor.org/demo, and a user guide, code examples,\\nand full API documentation are available at http://\\nchemdataextractor.org/docs. Data sets produced by Chem-\\nDataExtractor as part of the evaluation are available at http://\\nchemdataextractor.org/evaluation,\\nincluding melting points\\nextracted from 2000 patents and full data records extracted\\nfrom 50 journal articles.\\n\\navailable\\n\\n■ ACKNOWLEDGMENTS\\n\\nM.C.S. is grateful to the EPSRC for a DTA Ph.D. studentship\\n(Grant No. EP/J500380/1). J.M.C.\\nis indebted to the 1851\\nRoyal Commission for the 2014 Design Fellowship.\\n\\n■ REFERENCES\\n\\n(1) National Science and Technology Council, Oﬃce of Science and\\nTechnology Policy. Materials Genome Initiative for Global Competitive-\\nness; 2011.\\n(2) Olivares-Amaya, R.; Amador-Bedolla, C.; Hachmann, J.; Atahan-\\nEvrenk, S.; Sanchez-Carrera, R. S.; Vogt, L.; Aspuru-Guzik, A.\\nAccelerated Computational Discovery of High-performance Materials\\nfor Organic Photovoltaics by Means of Cheminformatics. Energy\\nEnviron. Sci. 2011, 4, 4849−4861.\\n(3) Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.;\\nDacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K.\\nA. Commentary: The Materials Project: A Materials Genome\\nApproach to Accelerating Materials Innovation. APL Mater. 2013, 1,\\n011002.\\n(4) Tsuruoka, Y.; Tateishi, Y.; Kim, J.-D.; Ohta, T.; McNaught, J.;\\nAnaniadou, S.; Tsujii, J. In Advances in Informatics; Bozanis, P., Houstis,\\nE. N., Eds.; Springer Berlin Heidelberg: Berlin, Heidelberg, 2005; pp\\n382−392.\\n(5) Fundel, K.; Küffner, R.; Zimmer, R. Relex\\ue0d5Relation Extraction\\nUsing Dependency Parse Trees. Bioinformatics 2007, 23, 365−371.\\n(6) Zweigenbaum, P.; Demner-Fushman, D.; Yu, H.; Cohen, K. B.\\nFrontiers of Biomedical Text Mining: Current Progress. Briefings\\nBioinf. 2007, 8, 358−375.\\n\\n1903\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\nJournal of Chemical Information and Modeling\\n\\nArticle\\n\\nJ. Challenges\\n\\n(7) Simpson, M. S.; Demner-Fushman, D. Mining Text Data;\\nSpringer US: Boston, MA, 2012; pp 465−517.\\n(8) Eltyeb, S.; Salim, N. Chemical Named Entities Recognition: A\\nReview on Approaches and Applications. J. Cheminf. 2014, 6, 17.\\n(9) Vazquez, M.; Krallinger, M.; Leitner, F.; Valencia, A. Text Mining\\nfor Drugs and Chemical Compounds: Methods, Tools and\\nApplications. Mol. Inf. 2011, 30, 506−519.\\n(10) Gurulingappa, H.; Mudi, A.; Toldo, L.; Hofmann-Apitius, M.;\\nBhate,\\nin Mining the Literature for Chemical\\nInformation. RSC Adv. 2013, 3, 16194−16211.\\n(11) Hawizy, L.;\\nJessop, D.; Adams, N.; Murray-Rust, P.\\nChemicalTagger: A Tool for Semantic Text-mining in Chemistry. J.\\nCheminf. 2011, 3, 17.\\n(12) Parr, T. J.; Quong, R. W. ANTLR: A Predicated-LL(k) Parser\\nGenerator. Software: Practice and Experience 1995, 25, 789−810.\\n(13) Jessop, D. M.; Adams, S. E.; Willighagen, E. L.; Hawizy, L.;\\nMurray-Rust, P. OSCAR4: A Flexible Architecture for Chemical Text-\\nmining. J. Cheminf. 2011, 3, 41.\\n(14) Lowe, D. M.; Sayle, R. A. LeadMine: A Grammar and\\nDictionary Driven Approach to Entity Recognition. J. Cheminf. 2015,\\n7, S5.\\n(15) Tetko, I. V.; Lowe, D. M.; Williams, A. J. The Development of\\nModels to Predict Melting and Pyrolysis Point Data Associated with\\nSeveral Hundred Thousand Compounds Mined from PATENTS. J.\\nCheminf. 2016, 8, 1−18.\\n(16) Tharatipyakul, A.; Numnark, S.; Wichadakul, D.; Ingsriswang, S.\\nChemEx: Information Extraction System for Chemical Data Curation.\\nBMC Bioinf. 2012, 13, S9.\\n(17) Filippov, I. V.; Nicklaus, M. C. Optical Structure Recognition\\nSoftware To Recover Chemical Information: OSRA, An Open Source\\nSolution. J. Chem. Inf. Model. 2009, 49, 740−743.\\n(18) Shinyama, Y. PDFMiner. https://euske.github.io/pdfminer/\\n(accessed October 3, 2016).\\n(19) Kiss, T.; Strunk,\\nBoundary Detection. Comput. Linguist. 2006, 32, 485−525.\\n(20) Read, J.; Dridan, R.; Oepen, S.; Solberg, L. J. Sentence Boundary\\nDetection: A Long Solved Problem? Proceedings of COLING 2012,\\nMumbia, India, December 2012; pp 985−994.\\n(21) Turian, J.; Ratinov, L.; Bengio, Y. Word representations: A\\nSimple and General Method for Semi-supervised Learning. Proceedings\\nof\\nthe Association for Computational\\nLinguistics, Uppsala, Sweden, July 11−16, 2010; pp384−394.\\n(22) Brown, P. F.; deSouza, P. V.; Mercer, R. L.; Pietra, V. J. D.; Lai,\\nJ. C. Class-based N-gram Models of Natural Language. Comput.\\nLinguist. 1992, 18, 467−479.\\n(23) Miller, S.; Guinness, J.; Zamanian, A. Name Tagging with Word\\nClusters and Discriminative Training. HLT/NAACL (Human\\nLanguage Technology conference/North American chapter of\\nthe\\nAssociation for Computational Linguistics annual meeting), Boston,\\nMassachusetts, May 2−7, 2004; pp 337−342.\\n(24) Ganchev, K.; Crammer, K.; Pereira, F.; Mann, G.; Bellare, K.;\\nCarroll, S.; Jin, Y.; White, P. Penn/Umass/CHOP Biocreative II Systems;\\n2007; pp 119−124.\\n(25) Täckström, O.; McDonald, R.; Uszkoreit, J. Cross-lingual Word\\nClusters for Direct Transfer of Linguistic Structure. HLT/NAACL,\\n2012; pp 477−487.\\n(26) Owoputi, O.; O’Connor, B.; Dyer, C.; Gimpel, K.; Schneider,\\nN.; Smith, N. A.\\nImproved Part-of-Speech Tagging for Online\\nConversational Text with Word Clusters. NAACL HLT 2013\\n(Proceedings of the 2013 Conference of the North American Chapter of\\nthe Association for Computational Linguistics: Human Language\\nTechnologies), Atlanta, Georgia, June 10−12, 2013; pp 380−390.\\n(27) Liang, P. Semi-Supervised Learning for Natural Language M.Sc.\\nthesis, Massachusetts Institute of Technology, 2005.\\n(28) Bies, A.; Mott, J.; Warner, C. English News Text Treebank: Penn\\nTreebank Revised LDC2015T13; Linguistic Data Consortium: Phila-\\ndelphia, 2015.\\n(29) Tateishi, Y.; Tsujii, J. Part-of-Speech Annotation of Biology\\nResearch Abstracts. LREC 2004 (Proceedings of the 4th International\\n\\nJ. Unsupervised Multilingual Sentence\\n\\nthe 48th Annual Meeting of\\n\\nConference on Language Resource and Evaluation), Lisbon, Portugal,\\nMay 26−28, 2004.\\n(30) Okazaki, N. CRFsuite: A Fast Implementation of Conditional\\nRandom Fields (CRFs). 2007; http://www.chokkan.org/software/\\ncrfsuite/ (accessed October 3, 2016).\\n(31) Rocktaschel, T.; Weidlich, M.; Leser, U. ChemSpot: A Hybrid\\nSystem for Chemical Named Entity Recognition. Bioinformatics 2012,\\n28, 1633−1640.\\n(32) Krallinger, M.; Leitner, F.; Rabal, O.; Vazquez, M.; Oyarzabal, J.;\\nValencia, A. CHEMDNER: The Drugs and Chemical Names\\nExtraction Challenge. J. Cheminf. 2015, 7, S1.\\n(33) Krallinger, M.; Rabal, O.; Leitner, F.; Vazquez, M.; Salgado, D.;\\nLu, Z.; Leaman, R.; Lu, Y.; Ji, D.; Lowe, D. M.; Sayle, R. A.; Batista-\\nNavarro, R. T.; Rak, R.; Huber, T.; Rocktäschel, T.; Matos, S.;\\nCampos, D.; Tang, B.; Xu, H.; Munkhdalai, T.; Ryu, K. H.; Ramanan,\\nS. V.; Nathan, S.; Žitnik, S.; Bajec, M.; Weber, L.; Irmer, M.; Akhondi,\\nS. A.; Kors, J. A.; Xu, S.; An, X.; Sikdar, U. K.; Ekbal, A.; Yoshioka, M.;\\nDieb, T. M.; Choi, M.; Verspoor, K.; Khabsa, M.; Giles, C. L.; Liu, H.;\\nRavikumar, K. E.; Lamurias, A.; Couto, F. M.; Dai, H.-J.; Tsai, R. T.;\\nAta, C.; Can, T.; Usié, A.; Alves, R.; Segura-Bedmar, I.; Martínez, P.;\\nOyarzabal, J.; Valencia, A. The CHEMDNER Corpus of Chemicals\\nand Drugs and Its Annotation Principles. J. Cheminf. 2015, 7, S2.\\n(34) Hettne, K. M.; Stierum, R. H.; Schuemie, M. J.; Hendriksen, P. J.\\nM.; Schijvenaars, B. J. A.; Mulligen, E. M. v.; Kleinjans, J.; Kors, J. A. A\\nDictionary to Identify Small Molecules and Drugs in Free Text.\\nBioinformatics 2009, 25, 2983−2991.\\n(35) Schwartz, A. S.; Hearst, M. A. A Simple Algorithm for\\nIdentifying Abbreviation Definitions in Biomedical Text. Proc. Pacific\\nSymp. 2003, 451.\\n(36) The manually-extracted gold standard output is available from\\nhttp://chemdataextractor.org/evaluation along with the full text of the\\n50 source articles.\\n(37) Leaman, R.; Wei, C.-H.; Lu, Z. tmChem: A High Performance\\nApproach for Chemical Named Entity Recognition and Normalization.\\nJ. Cheminf. 2015, 7, S3.\\n(38) Lu, Y.; Ji, D.; Yao, X.; Wei, X.; Liang, X. CHEMDNER System\\nwith Mixed Conditional Random Fields and Multi-Scale Word\\nClustering. J. Cheminf. 2015, 7, S4.\\n\\n1904\\n\\nDOI: 10.1021/acs.jcim.6b00207\\nJ. Chem. Inf. Model. 2016, 56, 1894−1904\\n\\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.plaintext()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a891b36",
   "metadata": {},
   "source": [
    "### Get Section titles and corresponding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f3fcc282",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'■ INTRODUCTION': ['Scientiﬁc results are typically communicated in the form of papers, patents, and theses that contain unstructured and semistructured data described by free-ﬂowing natural language that is not readily interpretable by machines. Yet, manual data abstraction by humans with expert knowledge is an expensive, labor-intensive, and error-prone process. With the continued growth of new publications, it is becoming increasingly diﬃcult to create and maintain up-to-date manually curated databases, and automated information extraction by machines is fast becoming a necessity.',\n",
       "  'The chemistry literature presents an attractive and tractable target for this automated extraction as it is typically comprised of formulaic, data-rich language that is well-suited for machine analysis with the potential for high recall and precision. The extracted chemical information can be used to create and populate databases of chemical structures, properties, and observations, opening up new avenues for discovery through large-scale data mining studies that are of great value in diverse areas such as materials discovery, drug discovery, and intellectual property protection.',\n",
       "  'In recent years, eﬀorts such as The Materials Genome Initiative1 have led to an increased focus on large-scale data- mining for materials discovery. Notable projects include the Harvard Clean Energy Project,2 which focuses on materials for organic photovoltaics, and the Materials Project,3 which focuses',\n",
       "  'on battery materials. These existing projects are primarily conﬁned to exploiting computational resources to predict chemical properties, an approach that would be well complemented by wider availability of machine-readable databases of experimental properties. Moreover, a generic method that can automatically generate a database for any type of material property would extend the reach of existing eﬀorts to all areas of materials science, rather than predeﬁning a focus on a speciﬁc area.',\n",
       "  'While there are many well-established text-mining tools in the biomedical domain,4−7 chemistry and materials text-mining is less widespread and fewer tools have been developed. Reviews by Eltyeb and Salim,8 Vazquez et al.,9 and Guru- lingappa et al.10 provide comprehensive overviews of the existing chemistry text-mining tools and methods. Most of these tools focus narrowly on extracting speciﬁc entity types from speciﬁc document domains, while there are relatively few methodologies that embrace a broader focus on the extraction of chemical including properties, experimental measurements, and relationships between entities.',\n",
       "  'information,',\n",
       "  'One such tool',\n",
       "  'is ChemicalTagger,11 which parses exper- imental synthesis sections of documents to determine chemical roles (e.g., reactant, solvent) and relationships with exper-',\n",
       "  'Received: April 13, 2016 Published: September 26, 2016',\n",
       "  '© 2016 American Chemical Society',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'imental actions (e.g., heated, stirred), through the use of an ANTLR grammar12 for rule-based text parsing and OSCAR13 for chemical named entity recognition. ChemicalTagger has been used in conjunction with the commercial tool LeadMine14 the extraction of melting points from patents,15 and for additionally, the ChemEx project16 extended ChemicalTagger with additional biomedical entity recognizers and image recognition of 2D chemical structures using OSRA.17',\n",
       "  'in particular, highlight',\n",
       "  'Gurulingappa et al.10 outline the various challenges to further progress, and, the distribution of information across diﬀerent components of documents, such as textual paragraphs, images, tables, and captions, as one of the primary barriers to successful extraction of chemical informa- tion.',\n",
       "  'In this paper, we present a comprehensive toolkit for the automated extraction of chemical information from scientiﬁc documents. The toolkit provides a complete natural language processing (NLP) pipeline that makes use of a wide range of state-of-the-art methods, including a chemistry-aware part-of- speech (POS) tagger, named entity recognizers that combine conditional random ﬁelds and dictionaries, rule-based gram- mars for phrase parsing, and word clustering to improve performance of machine learning methods through unsuper- vised training. In addition, the toolkit includes a table parser for extracting information from semistructured tabulated data, and document-level postprocessing algorithms to resolve data interdependencies between information extracted from diﬀer- ent parts of a document.',\n",
       "  'By automating the extraction of chemical entities, properties, measurements, and procedures, our toolkit enables vast chemical databases to be created and populated with minimal time, eﬀort, and expense.'],\n",
       " '■ IMPLEMENTATION': ['System Overview. Our system provides an end-to-end text-mining pipeline that takes PDF, HTML, and XML ﬁles as input and produces an output of machine-readable structured data that is suitable for depositing in a database. Figure 1 presents an overview of the system. Our approach to each stage of the process is described below.',\n",
       "  'Document Processing. The ﬁrst stage of the system is to process PDF, HTML, and XML ﬁles to isolate the relevant document domains, extract the raw text, and merge potentially fragmented data from diﬀerent sources to produce a complete document record. The end result is a consistent, simpliﬁed document structure that consists of a single linear stream of title, abstract, heading, paragraph, ﬁgure, and table document elements. This allows subsequent components in the pipeline',\n",
       "  'to process each document in exactly the same way, regardless of the original document format.',\n",
       "  'For text from HTML and XML sources, semantic markup of headings, paragraphs, captions and tables makes processing a trivial process. Once each text domain has been isolated, any further embedded markup (for example specifying bold and italic characters) is stripped to produce plain text for natural language processing. For tables, individual cells are treated as separate text domains, and stored in nested lists that represent the original table structure.',\n",
       "  'PDF documents present a greater challenge, as the format is not designed for the content to be easily interpreted by a machine. ChemDataExtractor provides layout analysis tools, built on top of the PDFMiner framework,18 that use the positions of images and text characters to group text into headings, paragraphs, and captions.',\n",
       "  'Natural Language Processing. The natural',\n",
       "  'language processing pipeline extracts structured information from the English-language text in headings, paragraphs, and captions. It is made up of ﬁve main stages: tokenization, part-of-speech tagging, named entity recognition, phrase parsing, and information extraction. Figure 2 shows an overview of the pipeline, alongside an illustration of each stage applied to an example text passage.',\n",
       "  'Tokenization. The tokenization process converts',\n",
       "  'text passages into a stream of tokens that are suitable for natural language processing. Text is ﬁrst split into sentences, and then each sentence is that broadly split further correspond to individual words and punctuation.',\n",
       "  'into tokens',\n",
       "  'Our system provides a sentence splitter that makes use of the Punkt algorithm by Kiss and Strunk,19 which detects sentence boundaries through unsupervised learning of common abbreviations and sentence starters. This algorithm has been shown to be broadly applicable to many languages and text domains, and performs best when it has been trained on text from the target domain.20 The unsupervised nature of this training process makes this method particularly well-suited to the chemistry domain, where there is a huge archive of literature available, and yet, very few collections have been manually annotated with features such as sentence boundaries. Our sentence splitter has been trained on the abstract, main text and captions of 3592 chemistry articles published by The American Chemical Society (ACS), The Royal Society of Chemistry (RSC), and Springer. The sentence splitter identiﬁes 702 132 individual sentences in the training articles, correctly distinguishing true sentence boundaries from full stops that occur in abbreviations, such as “et al.”, “ﬁg.”, “ref.”, and “equiv.” that are prevalent in the chemistry literature.',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  'providing a large collection of text from the target domain that has been manually annotated with the desired results. However, previous work has shown that these methods can be improved by adding unsupervised word representations as extra word features.21 This is particularly useful in the chemistry domain, where the relative lack of annotated text collections for supervised training can be compensated for by using word cluster features derived from the extensive and widely available unannotated literature.',\n",
       "  'the performance of',\n",
       "  'Our system makes use of',\n",
       "  'features derived from Brown clustering,22 a form of hierarchical clustering of words based on the contexts in which they occur. This has been shown to improve the performance of part-of-speech tagging and named entity recognition in a variety of domains.21,23−26 Figure 3 shows how various components of our natural language processing pipeline incorporate both unsupervised and supervised learning.',\n",
       "  '',\n",
       "  'from throughout',\n",
       "  'the document',\n",
       "  'The word tokenizer has been designed to broadly match the Penn Treebank policy, with some modiﬁcations to better handle chemistry text. Tokens are split on all whitespace and most punctuation characters, with exceptions for brackets, colons, and other symbols in certain situations to preserve entities such as chemical names as a single token. Additionally, care is taken to consistently split units and mathematical symbols from numeric values, regardless of whether the source text contains a space between them.',\n",
       "  'systems',\n",
       "  'to other',\n",
       "  'that normalize text prior',\n",
       "  'Text normalization is an important step that',\n",
       "  'removes commonly occurring inconsistencies that have a detrimental impact on the performance of machine learning and dictionary methods, and add unnecessary complexity to parsing rules. In contrast to tokenization, our tokenizer is designed to operate on any subsequently input, and normalization is unicode text performed on the text content of each individual token. The advantage of this approach is that each token can retain a pointer to its exact start and end position within the source text, even if normalization then changes the length of tokens. Therefore, the original token text can always be recovered, and any information derived about a token can be easily annotated back onto the original document.',\n",
       "  'As part of the normalization, unicode characters with similar appearance that are often used interchangeably are stand- ardized, all nonprinting control characters are removed, and alternative chemical spellings are uniﬁed.',\n",
       "  'Word Clustering. To achieve good performance, many machine learning techniques that are used in natural language processing must ﬁrst be trained in a supervised fashion by',\n",
       "  '',\n",
       "  'Clustering was performed on the full text and captions of 3592 chemistry articles published by the ACS, RSC, and Springer. Once tokenized, this collection consists of about 20 million words in about 700 000 sentences. Clustering was performed using the Liang C++ implementation27 to produce 1500 clusters containing 372 799 unique words. Figure 4 shows the highest frequency words in seven example clusters. As Brown clusters are hierarchical, diﬀerent length preﬁxes of the binary path correspond to cluster supersets, which can also be used as features in machine learning methods.',\n",
       "  'Part-of-Speech-Tagging. Part-of-speech (POS) tagging involves assigning a tag to each token that describes its syntactic function, for example as a noun, verb or adjective. Entity recognition, phrase parsing, and information extraction tools routinely use the POS tags on tokens as part of their input, and thus their success is often highly dependent on the accuracy of the tagging process.',\n",
       "  'The vast majority of publicly available natural',\n",
       "  'language processing tools provide POS taggers that have been trained on newspaper articles, and therefore do not necessarily perform well on chemistry literature. Tsuruoka et al.4 found that by training a POS tagger on a combined corpus of newspaper articles (WSJ corpus28) and MEDLINE abstracts (GENIA corpus29), performance in the biomedical domain was greatly',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'improved. In the absence of any equivalent POS-annotated corpus that covers the wider chemistry domain, the POS tagger in our system makes use of the same newspaper and biomedical training corpora but also supplements these with unsupervised word cluster features derived from chemistry articles. This improves performance across a wider range of subject areas and document domains (such as captions) that are not well-covered by the training corpora.',\n",
       "  'The POS tagger uses a linear-chain conditional random ﬁeld (CRF) model, trained using the orthant-wise limited-memory quasi-Newton (OWL-QN) method as implemented by the CRFsuite framework.30 The features for each token are shown in Table 1. The word shape feature is derived by replacing every',\n",
       "  '',\n",
       "  'a',\n",
       "  'feature',\n",
       "  'context',\n",
       "  'description',\n",
       "  'wi−2, wi−1, wi, wi+1, wi+2 wi−2wi−1, wi−1wi, wiwi+1,',\n",
       "  'wi+1wi+2',\n",
       "  'wi−2, wi−1, wi, wi+1, wi+2 wi−2, wi−1, wi, wi+1, wi+2',\n",
       "  'word bigrams',\n",
       "  'word shape Brown',\n",
       "  'clusters',\n",
       "  'length preﬁxes suﬃxes hyphenated alphabetical',\n",
       "  'case number punctuation',\n",
       "  'wi wi wi wi wi',\n",
       "  'wi wi wi',\n",
       "  'normalized lowercase token text combinations of consecutive',\n",
       "  'simpliﬁed token representation 4, 6, 10, and 20 bit binary path',\n",
       "  'tokens',\n",
       "  'preﬁxes',\n",
       "  'number of characters in token 1−5 character preﬁxes 1−5 character suﬃxes contains a hyphen character contains only alphabetical',\n",
       "  'characters',\n",
       "  'upper, lower, or title cased number in digit or word form contains only punctuation',\n",
       "  'characters',\n",
       "  'aA context window is used, such that some features for the token at index i are derived from the token text (w) of surrounding tokens.',\n",
       "  'number with “d”, every greek letter with “g”, and every latin letter with “X” or “x” for uppercase and lowercase, respectively. Chemical Named Entity Recognition. In order to extract information such as relations and properties, the named entities involved must ﬁrst be recognized. The task of recognizing chemical entity mentions in text is an area that has recently received signiﬁcant attention. The best performing approaches typically involve a hybrid approach that combines dictionary',\n",
       "  'and rule-based methods with machine learning methods. The OSCAR4 recognizer,13 which uses a maximum-entropy Markov model (MEMM), and ChemSpot,31 which uses a CRF model, are two of the most well-established systems. More recently, the CHEMDNER community challenge has promoted the development of a number of new systems32 and provided the CHEMDNER corpus of 10 000 PubMed abstracts with 84 355 manually annotated chemical entity mentions.33',\n",
       "  'Due to the wide variety of methods with diﬀering strengths, our approach is to provide a modular architecture for named from multiple entity recognition that allows the results methodologies to be combined using heuristic techniques. We primarily use a CRF-based recognizer for chemical names, in combination with a dictionary-based recognizer that provides improved performance for trivial and trade names, and a regular expression-based recognizer that excels for database identiﬁers and chemical formulas.',\n",
       "  'The dictionary-based recognizer uses a word list compiled from the Jochem chemical dictionary34 with an automatic ﬁltering process based on the method described by Lowe and Sayle14 that excludes entries that lead to false positives. For eﬃcient storage and fast string matching, the dictionary is stored as a directed acyclic word graph (DAWG), which uses a graph-like representation to eliminate redundancy between similar names.',\n",
       "  'The CRF-based recognizer uses a linear-chain CRF model, trained using the OWL-QN method as implemented by the CRFsuite framework.30 The features that are generated for each token are listed in Table 2. An “IOB” labeling scheme was utilized, where each token is labeled as the beginning of a chemical name (B), in a chemical name (I), or outside a chemical name (O). Training was performed using the training subset of the CHEMDNER corpus and the word clusters derived from chemistry articles.',\n",
       "  'Phrase Parsing. In general, parsing natural',\n",
       "  'language is a challenging problem, due to ambiguities that mean a single sentence can sometimes be parsed in multiple diﬀerent ways to produce diﬀerent meanings. In practice, the formulaic and precise nature of the chemistry literature means that this occurs less often, and parsing to a level that is adequate for information extraction is much more tractable than in other domains.',\n",
       "  'The ChemicalTagger project pioneered the use of a rule- based grammar for parsing experimental synthesis sections of',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'a',\n",
       "  'feature',\n",
       "  'context',\n",
       "  'description',\n",
       "  'wi−2, wi−1, wi, wi+1, wi+2 word wi−2, wi−1, wi, wi+1, wi+2 POS tags word shape wi−2, wi−1, wi, wi+1, wi+2 Brown clusters wi−2, wi−1, wi, wi+1, wi+2',\n",
       "  'normalized lowercase token text part-of-speech tag simpliﬁed token representation 4, 6, 10, and 20 bit binary path',\n",
       "  'length counts',\n",
       "  'preﬁxes suﬃxes hyphenated alphabetical',\n",
       "  'case number punctuation',\n",
       "  'wi wi',\n",
       "  'wi wi wi wi',\n",
       "  'wi wi wi',\n",
       "  'preﬁxes',\n",
       "  'counts',\n",
       "  'number of characters in token digit, upper, and lower case letter',\n",
       "  '1−5 character preﬁxes 1−5 character suﬃxes contains a hyphen character contains only alphabetical',\n",
       "  'characters',\n",
       "  'upper, lower, or title cased number in digit or word form contains only punctuation',\n",
       "  'characters',\n",
       "  'wi',\n",
       "  'URL aA context window is used, such that some features for the token at index i are derived from the token text (w) of surrounding tokens.',\n",
       "  'looks like a URL',\n",
       "  'chemistry texts. Their strategy was to attempt to build one universal grammar to parse all possible inputs, but this was pushing at the practical limits of a single rule-based grammar, even within their relatively narrow target domain.',\n",
       "  'Our alternative strategy is to make use of multiple, more specialized grammars that are tailored to extracting more speciﬁc types of chemical information. Similarly to Chem- icalTagger, our system produces input for the parser in the form of a merged list of tags from the part-of-speech tagger and chemical entity recognizer. Each grammar consists of a series of nested rules that describe how sequences of tagged tokens can be translated into a tree model that represents the syntactic structure of each sentence. Grammars are deﬁned in simple Python code, and unlike other tools, they do not need to be compiled before use.',\n",
       "  '',\n",
       "  '',\n",
       "  'that',\n",
       "  'recognizes',\n",
       "  'the | operator is used where just one of multiple alternatives is required. Additional elements such as Optional, Zer- oOrMore, and Not allow more complex rules to be constructed.',\n",
       "  'In the example grammar shown in Figure 5a, the ﬁrst rule, name, matches a token with the tag B-CM, followed by zero or more tokens with the tag I-CM, corresponding to the output tags of the chemical named entity recognizer. The second rule, label, deﬁnes two regular expression patterns, one for alphanumeric labels and one for Roman numerals, either of which may be matched. The ﬁnal rule, cem, is deﬁned in terms of the ﬁrst two rules. It requires a name, followed by a label enclosed within brackets. Figure 5b shows an illustration of the tree data structure that results from applying this grammar to an example sentence.',\n",
       "  '',\n",
       "  'An overview of the table parsing system is shown in Figure 6. At present, ChemDataExtractor primarily targets tables in',\n",
       "  '',\n",
       "  'which each row corresponds to a single chemical entity, and each column describes property values for that entity. By treating each individual table cell as a short, highly formulaic information can be extracted using a specialized sentence, language processing pipeline. This version of consists of a more ﬁne-grained tokenizer and a series of rule- based parsing grammars, each tailored speciﬁcally for extracting a certain property type.',\n",
       "  'the natural',\n",
       "  'Column headings are parsed ﬁrst, to determine the type of data in the cells below, as well as any relevant units. Column',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'headings can also contain contextual data themselves, such as temperatures, concentrations or solvent names, which are applied to the property values in every cell below that heading. Interpreting the property values in each cell can be as simple as reading a single numeric value, but multiple bracketed and',\n",
       "  'comma-separated values within a single cell are commonplace. In these cases, interpretation of any corresponding bracketed or comma-separated structure in the column heading is often necessary to successfully parse the values and assign the correct units to the correct values.',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  '',\n",
       "  'Data Interdependency Resolution. In many cases, the information extracted from a single sentence, caption or table can be meaningless or even misleading without the context provided by the rest of the document. The ﬁnal stage of our system involves postprocessing to resolve these data interdependencies and combine the data from individual document domains into a single complete structured record for each unique chemical entity that is mentioned in the document.',\n",
       "  'Chemical Identiﬁer Disambiguation. Initially, each heading, paragraph, caption and table is processed completely independently to produce structured chemical records that are deﬁned in terms of whatever chemical name, abbreviation, or identiﬁer is used locally in that context. The records from throughout the document are then combined into a single list, and records that refer to the same chemical entity are merged into a single record (Figure 7).',\n",
       "  'Our system detects deﬁnitions of chemical abbreviations and labels using a method based on the algorithm by Hearst and Schwartz.35 This algorithm is applied to all sentences in the document to produce a list of mappings between abbreviations and their corresponding full unabbreviated names. These mappings are then used to merge data that is deﬁned in terms of diﬀerent identiﬁers into single records for each unique chemical entity.',\n",
       "  'Global Contextual Information. In some cases, a sentence contains spectroscopic attributes or property information but is lacking any speciﬁc chemical identiﬁcation information. Often, for example in experimental sections of a research article, the identiﬁcation information may be available in the chemical preceding sentence or heading, and if so, this is used. Otherwise, typically contain contextual information (for example, a temperature, solvent, or apparatus) that is applicable to all properties or spectra of a certain type. In these cases, the information is merged into all other records for all spectra or properties of that type and the record itself is removed.',\n",
       "  'these sentences',\n",
       "  'Final Data Model. Figure 8 presents the schema of the ﬁnal data model. The extracted data are primarily based around chemical entity records that contain all the names, abbrevia- tions and labels that were used in the document to refer to a given chemical entity. Each chemical entity record can have multiple associated spectra and properties, and each spectrum can also optionally contain information about individual peaks. ChemDataExtractor comes with built-in parsers and extractors for the speciﬁc property and spectrum types shown in Figure 8; however, the extensible and modular design of ChemDataEx- tractor means that it is straightforward for users to build additional parsers and extractors for other property and spectrum types.',\n",
       "  'The ﬁnal chemical records may be saved directly to a document-oriented NoSQL database, or to a relational database',\n",
       "  'through the use of an object-relational mapper. Alternatively, they may be exported to a variety of ﬁle formats including Microsoft Excel, SDF, CSV, or JSON.'],\n",
       " '■ EVALUATION': ['Evaluation Metrics. For all aspects of',\n",
       "  'the system, performance has been evaluated in terms of precision (the percentage of retrieved results that are correct), recall (the percentage of correct results that are retrieved), and F-score (harmonic mean of precision and recall). These are deﬁned as',\n",
       "  'precision',\n",
       "  '=',\n",
       "  'recall',\n",
       "  '=',\n",
       "  'TP +',\n",
       "  'FP',\n",
       "  'TP',\n",
       "  'TP +',\n",
       "  'TP',\n",
       "  'FN',\n",
       "  '(1)',\n",
       "  '(2)',\n",
       "  'F score',\n",
       "  '‐',\n",
       "  '= · 2',\n",
       "  'precision recall',\n",
       "  '· +',\n",
       "  'precision',\n",
       "  'recall (3) where TP is a true positive that the system correctly identiﬁed, FP is a false positive that the system incorrectly identiﬁed, and FN is a false negative that the system failed to recognize.',\n",
       "  'Evaluation of Information Extraction from Academic Journals. Overall performance was evaluated by applying ChemDataExtractor to a test collection of 50 open-access chemistry articles that were selected from journals published by the ACS, RSC, and Springer. The precision, recall and F-score for the extraction of various diﬀerent kinds of information were calculated by comparing ChemDataExtractor’s output with a gold standard output36 that was manually compiled especially for this evaluation. Strict guidelines were developed to ensure manual extraction was performed consistently.',\n",
       "  'Chemical entities, spectra, and properties were extracted from the abstract, main text, tables, and ﬁgure captions. For this evaluation, extraction of melting point, oxidation and reduction potentials, photoluminescence lifetime, and quantum yield properties was considered, as well as NMR, UV−vis, and IR spectroscopic attributes. The relevant chemical entities were restricted to those with associated spectra or properties, or with an assigned alphanumeric label. All information that is deﬁned solely within a scheme or ﬁgure image or a separate Supporting Information document was considered outside the scope of our system and was therefore excluded from the evaluation.',\n",
       "  '',\n",
       "  '',\n",
       "  'chemical identiﬁer records spectrum records chemical property records',\n",
       "  'precision',\n",
       "  '94.1% 88.3% 93.5%',\n",
       "  'recall',\n",
       "  '92.7% 85.4% 89.6%',\n",
       "  'F-score',\n",
       "  '93.4% 86.8% 91.5%',\n",
       "  'attributes, and chemical properties. These evaluation metrics consider the extraction of an entire data record as an individual unit, as shown by the schema diagram in Figure 8. A record is considered a false negative if any part of the record is missing, a false positive if any part of the record is incorrect, and a true positive only if it is exactly correct.',\n",
       "  'The following sections present a more detailed evaluation of the individual components that make up each of the record types in Table 3.',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  'Chemical',\n",
       "  'ChemDataExtractor’s ability to extract',\n",
       "  'Identiﬁers. Table 4 presents an evaluation of the names and',\n",
       "  '',\n",
       "  'chemical names alphanumeric labels full chemical identiﬁer records',\n",
       "  'precision',\n",
       "  '97.4% 99.3% 94.1%',\n",
       "  'recall',\n",
       "  '96.3% 97.3% 92.7%',\n",
       "  'F-score',\n",
       "  '96.8% 98.3% 93.4%',\n",
       "  'alphanumeric labels of chemical entities in a document. Any identiﬁer that is present in public chemical databases or is resolvable using IUPAC naming rules is considered a name, while all other identiﬁers that are typically only applicable within the context of the containing document are considered labels.',\n",
       "  'Chemical name extraction is primarily dependent on the the underlying chemical named entity performance of recognizers, while extraction of labels depends on their proximity to a recognized chemical name or their presence within a table.',\n",
       "  'An F-score of 93.4% was obtained when considering chemical records as a whole, reﬂecting ChemDataExtractor’s ability to identify which names and alphanumeric labels correspond to the same chemical entity. Accurately matching alphanumeric labels to the relevant chemical name is a vital prerequisite to successfully extracting any spectra and proper- ties that are deﬁned solely in terms of a label.',\n",
       "  'Spectroscopic Attributes. An evaluation of ChemDataEx- tractor’s ability to extract various spectroscopic attributes is shown in Table 5. As well as assessing the extraction of each individual spectrum attribute, the extraction of overall spectrum records is presented.',\n",
       "  '',\n",
       "  'spectrum type chemical subject peak values solvent temperature apparatus full spectrum records',\n",
       "  'precision',\n",
       "  '99.9% 93.4% 98.6% 99.5% 100% 96.9% 88.3%',\n",
       "  'recall',\n",
       "  '96.7% 90.3% 95.4% 96.7% 87.5% 91.0% 85.4%',\n",
       "  'F-score',\n",
       "  '98.4% 91.8% 96.9% 98.1% 93.3% 93.8% 86.8%',\n",
       "  'Precision is consistently high across all attributes, and some even have no false positives at all within the test set. This is due to the rule-based nature of the parsers in ChemDataExtractor, which are well-suited to the formulaic language and structure of scientiﬁc articles that leave little room for misinterpretation.',\n",
       "  'Contextual spectroscopic attributes such as temperature and apparatus present the greatest challenge in terms of resolving interdependencies between information that has been extracted from diﬀerent document domains. For example, a spectrum may have peaks listed in a table, temperature mentioned in a ﬁgure caption, and apparatus mentioned in the main text, leading to the slightly lower recall values of 87.5% and 91.0% for temperature and apparatus, respectively. The ability to accurately match together these disparate pieces of information is a unique strength of ChemDataExtractor, yet also presents the greatest opportunity for further improvement.',\n",
       "  'Chemical Properties. Table 6 presents the precision, recall, and F-score for the extraction of diﬀerent aspects of chemical property information, as well as the overall property record.',\n",
       "  '',\n",
       "  'property value property units chemical subject solvent temperature apparatus full property records',\n",
       "  'precision',\n",
       "  '100% 100% 93.5% 100% 100% 100% 93.5%',\n",
       "  'recall',\n",
       "  '95.9% 94.8% 89.6% 94.4% 88.9% 87.5% 89.6%',\n",
       "  '',\n",
       "  'F-score',\n",
       "  '97.9% 97.4% 91.5% 97.1% 94.1% 93.3% 91.5%',\n",
       "  'Errors in property extraction typically occur where properties are reported in sentences within the main text, rather than in a table. In these cases, while the value and units are normally issue, complex sentence structures often extracted without result in a failure to assign a chemical subject. Errors in extraction from tables also occasionally arise from complex table structures; for example where some table cells are merged across multiple rows or columns, as this can introduce ambiguity around the exact scope of the cell contents.',\n",
       "  'Evaluation of Information Extraction from Patents. The performance of ChemDataExtractor was also tested against patent documents. To this end, a case study on melting points was used for the evaluation since it oﬀers a good comparison to the recent work of Tetko et al.,15 who have generated a data set of 241 958 melting points, which were mined from US patents using LeadMine14 in combination with a customized version of ChemicalTagger.11 A comparative evaluation was performed by applying ChemDataExtractor to a representative subset of the patents used in their study and comparing the extracted melting point records from the two generated data sets. The subset comprised a sample of 2000 patents, which were drawn from a random selection of US patent grants that were published in the years 2005−2014 and were present in the melting point data set published by Tetko et al.',\n",
       "  'In total, ChemDataExtractor obtained 18 180 unique melting points while Tetko et al. obtained 13 198 from this sample. There is an overlap of 8978 melting points that match exactly between the two data sets, giving a shared total of 22 400 in addition to the 8978 unique melting points. Therefore, (40%) that are common to both data sets, there are 9202 (41%) that occur only in the ChemDataExtractor data set and 4220 (19%) that occur only in the Tetko data set. These nonmatching subsets include a further 202 compounds that are present in both data sets but with diﬀering melting point values. Of the overall set of 9180 common compounds, 97.8% have identical melting points, while the remaining melting point pairings diﬀer by a root mean squared deviation of 63 °C.',\n",
       "  'When interpreting these values, it is important to note that Tetko et al. removed duplicate values across their entire data set, prior to the evaluation sample being taken, while the ChemDataExtractor duplicate values were only removed by considering the evaluation sample itself. The published Tetko data set only references a single patent for each melting point, even if it was extracted from multiple ones, so many of the melting point values that appear to be missing from the LeadMine-extracted evaluation sample from 2000 patents were in fact intentionally discarded because they were considered to',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  'be a duplicate of a value from another patent outside the sample. Also, 2557 compounds for which melting points appear to have been only extracted by ChemDataExtractor do in fact occur in the overall Tetko data set as extracted from a diﬀerent patent. If the beneﬁt of the doubt is given and all of these cases are assumed to be duplicate removals, 11 535 (51%) of values are common to both tools, 6645 (30%) occur only in the ChemDataExtractor data set, and 4220 (19%) occur only in the Tetko data set. Tetko et al. also discarded an unspeciﬁed number of melting points that failed with descriptor calculation programs, which may further account for diﬀerences between the two data sets.',\n",
       "  'Despite these diﬀerences, Table 7 shows that there is good agreement between the data sets in terms of this classiﬁcation',\n",
       "  '',\n",
       "  'a',\n",
       "  'data set',\n",
       "  'count',\n",
       "  'average MW',\n",
       "  'average NA',\n",
       "  'ChemDataExtractor Tetko Tetko (all) aValues for the entire Tetko dataset are also shown for comparison.',\n",
       "  '18180 13198 241958',\n",
       "  '385.5 385.1 357',\n",
       "  '26.9 27.0 25.0',\n",
       "  'average T (°C) 166.3 164.1 159',\n",
       "  'according to the average melting point temperature, average molecular weight, and average number of non-hydrogen atoms in the compounds involved. Moreover, Figure 9 shows broad agreement in the distribution of melting point temperatures for the diﬀerent data sets, including being able to reproduce the peaks at 250 and 300 °C.',\n",
       "  'Evaluation of Natural Language Processing Compo- nents. The performance of each individual component in the language processing pipeline can place an eﬀective natural upper bound on the ability to accurately extract information. Imperfect performance in earlier stages carries through the pipeline and can degrade the performance of each subsequent',\n",
       "  '',\n",
       "  'stage. For example, incorrect POS tags can have a direct negative impact on both the recognition of chemical entities and the parsing of a sentence. Likewise, missing or incorrectly recognized chemical entity names can invalidate the extraction of all associated spectroscopic data and properties.',\n",
       "  'Therefore,',\n",
       "  'it is important to quantify the performance of each component to identify the greatest barriers to improved performance of the overall system.',\n",
       "  'Chemical Entity Mentions. To facilitate comparison with other text mining tools, recognition of individual chemical mentions was evaluated. This evaluation was performed using the CHEMDNER corpus.33 This consists of 3000 abstracts from across the chemistry domain that have been manually annotated with 25 351 chemical entity mentions. Results were calculated using the bc-evaluate tool provided by the CHEMDNER organizers.',\n",
       "  '',\n",
       "  '',\n",
       "  'system',\n",
       "  'precision',\n",
       "  'CRF dictionary regular expression combined system',\n",
       "  '90.5% 88.6% 89.4% 89.1%',\n",
       "  'recall',\n",
       "  '80.0% 70.2% 11.0% 86.6%',\n",
       "  'F-score',\n",
       "  '84.9% 78.3% 19.6% 87.8%',\n",
       "  'of the chemical entity recognition system, as well as for the overall combined system. The overall combined F-score of 87.8% exceeds the scores achieved by all the tools that oﬃcially entered the CHEMDNER chemical names extraction chal- lenge.32 The two best entries were tmChem by Leaman et al.,37 which achieved an F-score of 87.39%, and a system by Lu et al.,38 which achieved an F-score of 87.11%. Lu et al. have since published an alternative version of their system that achieved an F-score of 88.06%, which outperforms ChemDataExtractor on this statistic by 0.3%.',\n",
       "  'The CRF recognizer with word cluster features is the best performing individual component, with an F-score of 84.9%. While the dictionary recognizer has similar precision to the CRF, it has inferior recall, primarily caused by poor recognition of systematic names and chemical formulas. This weakness is typical of dictionary-based methods, where each chemical name must be present in the dictionary for it to be successfully recognized.',\n",
       "  'The regular expression recognizer',\n",
       "  'is only designed to recognize a limited set of chemical identiﬁer patterns, such as database registry numbers and chemical formulas, and therefore just 11.0% when applied on its own. has poor recall of identiﬁers can pose the However, these types of chemical greatest diﬃculty for the CRF and dictionary methods, and therefore the regular expression component still makes a worthwhile contribution to the overall combined system.',\n",
       "  'POS Tagging. POS tagging performance was evaluated two diﬀerent corpora that have been through the use of manually annotated with POS tags: The Wall Street Journal (WSJ) corpus,28 which consists of 1 million words from 1989 Wall Street Journal news articles, and the GENIA corpus,29 which consists of 2000 MEDLINE abstracts that cover the biomedical domain. The standard WSJ splitting convention was',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  'used, with sections 0−18 for training, 19−21 for development, and 22−24 for evaluation. The ﬁrst 90% of the GENIA corpus was used for training, and the remaining 10% for evaluation, matching the split used by Tsuruoka et al.4 in developing a biomedical POS tagger.',\n",
       "  '',\n",
       "  '',\n",
       "  'training system',\n",
       "  'WSJ WSJ + clusters GENIA GENIA + clusters WSJ + GENIA WSJ + GENIA + clusters',\n",
       "  'WSJ',\n",
       "  '97.19% 97.23% 78.88% 81.19% 97.02% 97.08%',\n",
       "  'GENIA',\n",
       "  '83.50% 84.15% 98.53% 98.62% 98.26% 98.34%',\n",
       "  'corpora. Supervised training was performed using the WSJ and GENIA training corpora individually, and also both combined. The eﬀect of adding unsupervised features from word clusters was also evaluated on each of these three conﬁgurations.',\n",
       "  'Taggers trained individually on either the WSJ or the GENIA corpus achieved the best performance when evaluated on that same corpus but aﬀorded the poorest performance when evaluated on the opposite corpus. The tagger trained on the WSJ training corpus achieved an accuracy of 97.23% on the WSJ evaluation corpus, which falls to 84.15% on the GENIA evaluation corpus. Likewise, the tagger trained on the GENIA training corpus achieved an accuracy of 98.62% on the GENIA evaluation corpus, which falls to 81.19% on the WSJ evaluation corpus.',\n",
       "  'The tagger trained on the combined WSJ and GENIA corpora achieves good accuracy on both evaluation corpora, with 97.08% on the WSJ evaluation corpus and 98.34% on the GENIA evaluation corpus. This matches the observations of Tsuruoka et al., indicating that using the combined newspaper and biomedical training sets extends coverage over both and has little negative impact compared to the specialized training for a speciﬁc domain.',\n",
       "  'The addition of word cluster features has a positive eﬀect in all cases, but this is most signiﬁcant in the cases where there is a mismatch between the training corpus and the evaluation corpus. The accuracy of the WSJ-trained tagger on the GENIA corpus rises from 83.50% to 84.15%, and the accuracy of the GENIA-trained tagger on the WSJ corpus rises from 78.88% to 81.19%. This suggests that unsupervised word cluster features are capable of broadening the coverage of a POS tagger outside the domain of its supervised training and, therefore, should lead to improved performance across the wider chemistry domain for the tagger trained on the combined WSJ and GENIA',\n",
       "  'corpus.■ CONCLUSIONS',\n",
       "  'ChemDataExtractor is able to automatically extract chemical information from scientiﬁc documents, facilitating the creation of massive chemical databases with minimal time and eﬀort. The system consists of a modular document processing pipeline with extensible components for natural language processing that achieve state-of-the-art performance for POS tagging and chemical named entity recognition.',\n",
       "  '',\n",
       "  'In contrast to most existing text-mining systems that focus on extracting entities from individual sentences, ChemDataEx- tractor provides a table processor for extraction of tabulated experimental properties and document-level processing algo- rithms to resolve data interdependencies and produce uniﬁed chemical records that incorporate information from multiple document domains. Evaluations demonstrate good perform- ance in the extraction of chemical entities and their associated experimental properties and spectroscopic data.',\n",
       "  'The generic and extensible design of the system means it can applied to the extraction of any chemical properties, measure- ments and relationships with minimal additional eﬀort. This leads to the ultimate goal of quickly autogenerating chemical structure and property databases for materials science and other ﬁelds. Future work will focus on extending the system to further property and spectrum types, and improving the performance of language processing components.',\n",
       "  'individual natural'],\n",
       " '■ AUTHOR INFORMATION': ['Corresponding Author *E-mail: jmc61@cam.ac.uk. Notes The authors declare no competing ﬁnancial interest. ChemDataExtractor is released under the MIT license and is available to download from http://chemdataextractor.org. An interactive on line d emo is at h ttp :// chemdataextractor.org/demo, and a user guide, code examples, and full API documentation are available at http:// chemdataextractor.org/docs. Data sets produced by Chem- DataExtractor as part of the evaluation are available at http:// chemdataextractor.org/evaluation, including melting points extracted from 2000 patents and full data records extracted from 50 journal articles.',\n",
       "  'available'],\n",
       " '■ ACKNOWLEDGMENTS': ['M.C.S. is grateful to the EPSRC for a DTA Ph.D. studentship (Grant No. EP/J500380/1). J.M.C. is indebted to the 1851 Royal Commission for the 2014 Design Fellowship.'],\n",
       " '■ REFERENCES': ['(1) National Science and Technology Council, Oﬃce of Science and Technology Policy. Materials Genome Initiative for Global Competitive- ness; 2011. (2) Olivares-Amaya, R.; Amador-Bedolla, C.; Hachmann, J.; Atahan- Evrenk, S.; Sanchez-Carrera, R. S.; Vogt, L.; Aspuru-Guzik, A. Accelerated Computational Discovery of High-performance Materials for Organic Photovoltaics by Means of Cheminformatics. Energy Environ. Sci. 2011, 4, 4849−4861. (3) Jain, A.; Ong, S. P.; Hautier, G.; Chen, W.; Richards, W. D.; Dacek, S.; Cholia, S.; Gunter, D.; Skinner, D.; Ceder, G.; Persson, K. A. Commentary: The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation. APL Mater. 2013, 1, 011002. (4) Tsuruoka, Y.; Tateishi, Y.; Kim, J.-D.; Ohta, T.; McNaught, J.; Ananiadou, S.; Tsujii, J. In Advances in Informatics; Bozanis, P., Houstis, E. N., Eds.; Springer Berlin Heidelberg: Berlin, Heidelberg, 2005; pp 382−392. (5) Fundel, K.; Küffner, R.; Zimmer, R. Relex\\ue0d5Relation Extraction Using Dependency Parse Trees. Bioinformatics 2007, 23, 365−371. (6) Zweigenbaum, P.; Demner-Fushman, D.; Yu, H.; Cohen, K. B. Frontiers of Biomedical Text Mining: Current Progress. Briefings Bioinf. 2007, 8, 358−375.',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904',\n",
       "  '',\n",
       "  '',\n",
       "  'J. Challenges',\n",
       "  '(7) Simpson, M. S.; Demner-Fushman, D. Mining Text Data; Springer US: Boston, MA, 2012; pp 465−517. (8) Eltyeb, S.; Salim, N. Chemical Named Entities Recognition: A Review on Approaches and Applications. J. Cheminf. 2014, 6, 17. (9) Vazquez, M.; Krallinger, M.; Leitner, F.; Valencia, A. Text Mining for Drugs and Chemical Compounds: Methods, Tools and Applications. Mol. Inf. 2011, 30, 506−519. (10) Gurulingappa, H.; Mudi, A.; Toldo, L.; Hofmann-Apitius, M.; Bhate, in Mining the Literature for Chemical Information. RSC Adv. 2013, 3, 16194−16211. (11) Hawizy, L.; Jessop, D.; Adams, N.; Murray-Rust, P. ChemicalTagger: A Tool for Semantic Text-mining in Chemistry. J. Cheminf. 2011, 3, 17. (12) Parr, T. J.; Quong, R. W. ANTLR: A Predicated-LL(k) Parser Generator. Software: Practice and Experience 1995, 25, 789−810. (13) Jessop, D. M.; Adams, S. E.; Willighagen, E. L.; Hawizy, L.; Murray-Rust, P. OSCAR4: A Flexible Architecture for Chemical Text- mining. J. Cheminf. 2011, 3, 41. (14) Lowe, D. M.; Sayle, R. A. LeadMine: A Grammar and Dictionary Driven Approach to Entity Recognition. J. Cheminf. 2015, 7, S5. (15) Tetko, I. V.; Lowe, D. M.; Williams, A. J. The Development of Models to Predict Melting and Pyrolysis Point Data Associated with Several Hundred Thousand Compounds Mined from PATENTS. J. Cheminf. 2016, 8, 1−18. (16) Tharatipyakul, A.; Numnark, S.; Wichadakul, D.; Ingsriswang, S. ChemEx: Information Extraction System for Chemical Data Curation. BMC Bioinf. 2012, 13, S9. (17) Filippov, I. V.; Nicklaus, M. C. Optical Structure Recognition Software To Recover Chemical Information: OSRA, An Open Source Solution. J. Chem. Inf. Model. 2009, 49, 740−743. (18) Shinyama, Y. PDFMiner. https://euske.github.io/pdfminer/ (accessed October 3, 2016). (19) Kiss, T.; Strunk, Boundary Detection. Comput. Linguist. 2006, 32, 485−525. (20) Read, J.; Dridan, R.; Oepen, S.; Solberg, L. J. Sentence Boundary Detection: A Long Solved Problem? Proceedings of COLING 2012, Mumbia, India, December 2012; pp 985−994. (21) Turian, J.; Ratinov, L.; Bengio, Y. Word representations: A Simple and General Method for Semi-supervised Learning. Proceedings of the Association for Computational Linguistics, Uppsala, Sweden, July 11−16, 2010; pp384−394. (22) Brown, P. F.; deSouza, P. V.; Mercer, R. L.; Pietra, V. J. D.; Lai, J. C. Class-based N-gram Models of Natural Language. Comput. Linguist. 1992, 18, 467−479. (23) Miller, S.; Guinness, J.; Zamanian, A. Name Tagging with Word Clusters and Discriminative Training. HLT/NAACL (Human Language Technology conference/North American chapter of the Association for Computational Linguistics annual meeting), Boston, Massachusetts, May 2−7, 2004; pp 337−342. (24) Ganchev, K.; Crammer, K.; Pereira, F.; Mann, G.; Bellare, K.; Carroll, S.; Jin, Y.; White, P. Penn/Umass/CHOP Biocreative II Systems; 2007; pp 119−124. (25) Täckström, O.; McDonald, R.; Uszkoreit, J. Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure. HLT/NAACL, 2012; pp 477−487. (26) Owoputi, O.; O’Connor, B.; Dyer, C.; Gimpel, K.; Schneider, N.; Smith, N. A. Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters. NAACL HLT 2013 (Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies), Atlanta, Georgia, June 10−12, 2013; pp 380−390. (27) Liang, P. Semi-Supervised Learning for Natural Language M.Sc. thesis, Massachusetts Institute of Technology, 2005. (28) Bies, A.; Mott, J.; Warner, C. English News Text Treebank: Penn Treebank Revised LDC2015T13; Linguistic Data Consortium: Phila- delphia, 2015. (29) Tateishi, Y.; Tsujii, J. Part-of-Speech Annotation of Biology Research Abstracts. LREC 2004 (Proceedings of the 4th International',\n",
       "  'J. Unsupervised Multilingual Sentence',\n",
       "  'the 48th Annual Meeting of',\n",
       "  'Conference on Language Resource and Evaluation), Lisbon, Portugal, May 26−28, 2004. (30) Okazaki, N. CRFsuite: A Fast Implementation of Conditional Random Fields (CRFs). 2007; http://www.chokkan.org/software/ crfsuite/ (accessed October 3, 2016). (31) Rocktaschel, T.; Weidlich, M.; Leser, U. ChemSpot: A Hybrid System for Chemical Named Entity Recognition. Bioinformatics 2012, 28, 1633−1640. (32) Krallinger, M.; Leitner, F.; Rabal, O.; Vazquez, M.; Oyarzabal, J.; Valencia, A. CHEMDNER: The Drugs and Chemical Names Extraction Challenge. J. Cheminf. 2015, 7, S1. (33) Krallinger, M.; Rabal, O.; Leitner, F.; Vazquez, M.; Salgado, D.; Lu, Z.; Leaman, R.; Lu, Y.; Ji, D.; Lowe, D. M.; Sayle, R. A.; Batista- Navarro, R. T.; Rak, R.; Huber, T.; Rocktäschel, T.; Matos, S.; Campos, D.; Tang, B.; Xu, H.; Munkhdalai, T.; Ryu, K. H.; Ramanan, S. V.; Nathan, S.; Žitnik, S.; Bajec, M.; Weber, L.; Irmer, M.; Akhondi, S. A.; Kors, J. A.; Xu, S.; An, X.; Sikdar, U. K.; Ekbal, A.; Yoshioka, M.; Dieb, T. M.; Choi, M.; Verspoor, K.; Khabsa, M.; Giles, C. L.; Liu, H.; Ravikumar, K. E.; Lamurias, A.; Couto, F. M.; Dai, H.-J.; Tsai, R. T.; Ata, C.; Can, T.; Usié, A.; Alves, R.; Segura-Bedmar, I.; Martínez, P.; Oyarzabal, J.; Valencia, A. The CHEMDNER Corpus of Chemicals and Drugs and Its Annotation Principles. J. Cheminf. 2015, 7, S2. (34) Hettne, K. M.; Stierum, R. H.; Schuemie, M. J.; Hendriksen, P. J. M.; Schijvenaars, B. J. A.; Mulligen, E. M. v.; Kleinjans, J.; Kors, J. A. A Dictionary to Identify Small Molecules and Drugs in Free Text. Bioinformatics 2009, 25, 2983−2991. (35) Schwartz, A. S.; Hearst, M. A. A Simple Algorithm for Identifying Abbreviation Definitions in Biomedical Text. Proc. Pacific Symp. 2003, 451. (36) The manually-extracted gold standard output is available from http://chemdataextractor.org/evaluation along with the full text of the 50 source articles. (37) Leaman, R.; Wei, C.-H.; Lu, Z. tmChem: A High Performance Approach for Chemical Named Entity Recognition and Normalization. J. Cheminf. 2015, 7, S3. (38) Lu, Y.; Ji, D.; Yao, X.; Wei, X.; Liang, X. CHEMDNER System with Mixed Conditional Random Fields and Multi-Scale Word Clustering. J. Cheminf. 2015, 7, S4.',\n",
       "  '',\n",
       "  'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016, 56, 1894−1904']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf.section()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da331573",
   "metadata": {},
   "source": [
    "### Get References"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "132b5bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "['National Science and Technology Council', ' Oﬃce of Science and Technology Policy. Materials Genome Initiative for Global Competitive- ness; 2011. ']\n",
      "1\n",
      "['Olivares-Amaya', ' R.; Amador-Bedolla', ' C.; Hachmann', ' J.; Atahan- Evrenk', ' S.; Sanchez-Carrera', ' R. S.; Vogt', ' L.; Aspuru-Guzik', ' A. Accelerated Computational Discovery of High-performance Materials for Organic Photovoltaics by Means of Cheminformatics. Energy Environ. Sci. 2011', ' 4', ' 4849−4861. ']\n",
      "2\n",
      "['Jain', ' A.; Ong', ' S. P.; Hautier', ' G.; Chen', ' W.; Richards', ' W. D.; Dacek', ' S.; Cholia', ' S.; Gunter', ' D.; Skinner', ' D.; Ceder', ' G.; Persson', ' K. A. Commentary: The Materials Project: A Materials Genome Approach to Accelerating Materials Innovation. APL Mater. 2013', ' 1', ' 011002. ']\n",
      "3\n",
      "['Tsuruoka', ' Y.; Tateishi', ' Y.; Kim', ' J.-D.; Ohta', ' T.; McNaught', ' J.; Ananiadou', ' S.; Tsujii', ' J. In Advances in Informatics; Bozanis', ' P.', ' Houstis', ' E. N.', ' Eds.; Springer Berlin Heidelberg: Berlin', ' Heidelberg', ' 2005; pp 382−392. ']\n",
      "4\n",
      "['Fundel', ' K.; Küffner', ' R.; Zimmer', ' R. Relex\\\\ue0d5Relation Extraction Using Dependency Parse Trees. Bioinformatics 2007', ' 23', ' 365−371. ']\n",
      "5\n",
      "['Zweigenbaum', ' P.; Demner-Fushman', ' D.; Yu', ' H.; Cohen', ' K. B. Frontiers of Biomedical Text Mining: Current Progress. Briefings Bioinf. 2007', ' 8', \" 358−375.'\", \" ''\", \" 'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016\", ' 56', \" 1894−1904'\", \" ''\", \" ''\", \" 'J. Challenges'\", \" '\"]\n",
      "6\n",
      "['Simpson', ' M. S.; Demner-Fushman', ' D. Mining Text Data; Springer US: Boston', ' MA', ' 2012; pp 465−517. ']\n",
      "7\n",
      "['Eltyeb', ' S.; Salim', ' N. Chemical Named Entities Recognition: A Review on Approaches and Applications. J. Cheminf. 2014', ' 6', ' 17. ']\n",
      "8\n",
      "['Vazquez', ' M.; Krallinger', ' M.; Leitner', ' F.; Valencia', ' A. Text Mining for Drugs and Chemical Compounds: Methods', ' Tools and Applications. Mol. Inf. 2011', ' 30', ' 506−519. ']\n",
      "9\n",
      "['Gurulingappa', ' H.; Mudi', ' A.; Toldo', ' L.; Hofmann-Apitius', ' M.; Bhate', ' in Mining the Literature for Chemical Information. RSC Adv. 2013', ' 3', ' 16194−16211. ']\n",
      "10\n",
      "['Hawizy', ' L.; Jessop', ' D.; Adams', ' N.; Murray-Rust', ' P. ChemicalTagger: A Tool for Semantic Text-mining in Chemistry. J. Cheminf. 2011', ' 3', ' 17. ']\n",
      "11\n",
      "['Parr', ' T. J.; Quong', ' R. W. ANTLR: A Predicated-LL(k) Parser Generator. Software: Practice and Experience 1995', ' 25', ' 789−810. ']\n",
      "12\n",
      "['Jessop', ' D. M.; Adams', ' S. E.; Willighagen', ' E. L.; Hawizy', ' L.; Murray-Rust', ' P. OSCAR4: A Flexible Architecture for Chemical Text- mining. J. Cheminf. 2011', ' 3', ' 41. ']\n",
      "13\n",
      "['Lowe', ' D. M.; Sayle', ' R. A. LeadMine: A Grammar and Dictionary Driven Approach to Entity Recognition. J. Cheminf. 2015', ' 7', ' S5. ']\n",
      "14\n",
      "['Tetko', ' I. V.; Lowe', ' D. M.; Williams', ' A. J. The Development of Models to Predict Melting and Pyrolysis Point Data Associated with Several Hundred Thousand Compounds Mined from PATENTS. J. Cheminf. 2016', ' 8', ' 1−18. ']\n",
      "15\n",
      "['Tharatipyakul', ' A.; Numnark', ' S.; Wichadakul', ' D.; Ingsriswang', ' S. ChemEx: Information Extraction System for Chemical Data Curation. BMC Bioinf. 2012', ' 13', ' S9. ']\n",
      "16\n",
      "['Filippov', ' I. V.; Nicklaus', ' M. C. Optical Structure Recognition Software To Recover Chemical Information: OSRA', ' An Open Source Solution. J. Chem. Inf. Model. 2009', ' 49', ' 740−743. ']\n",
      "17\n",
      "['Shinyama', ' Y. PDFMiner. https://euske.github.io/pdfminer/ (accessed October 3', ' 2016). ']\n",
      "18\n",
      "['Kiss', ' T.; Strunk', ' Boundary Detection. Comput. Linguist. 2006', ' 32', ' 485−525. ']\n",
      "19\n",
      "['Read', ' J.; Dridan', ' R.; Oepen', ' S.; Solberg', ' L. J. Sentence Boundary Detection: A Long Solved Problem? Proceedings of COLING 2012', ' Mumbia', ' India', ' December 2012; pp 985−994. ']\n",
      "20\n",
      "['Turian', ' J.; Ratinov', ' L.; Bengio', ' Y. Word representations: A Simple and General Method for Semi-supervised Learning. Proceedings of the Association for Computational Linguistics', ' Uppsala', ' Sweden', ' July 11−16', ' 2010; pp384−394. ']\n",
      "21\n",
      "['Brown', ' P. F.; deSouza', ' P. V.; Mercer', ' R. L.; Pietra', ' V. J. D.; Lai', ' J. C. Class-based N-gram Models of Natural Language. Comput. Linguist. 1992', ' 18', ' 467−479. ']\n",
      "22\n",
      "['Miller', ' S.; Guinness', ' J.; Zamanian', ' A. Name Tagging with Word Clusters and Discriminative Training. HLT/NAACL (Human Language Technology conference/North American chapter of the Association for Computational Linguistics annual meeting)', ' Boston', ' Massachusetts', ' May 2−7', ' 2004; pp 337−342. ']\n",
      "23\n",
      "['Ganchev', ' K.; Crammer', ' K.; Pereira', ' F.; Mann', ' G.; Bellare', ' K.; Carroll', ' S.; Jin', ' Y.; White', ' P. Penn/Umass/CHOP Biocreative II Systems; 2007; pp 119−124. ']\n",
      "24\n",
      "['Täckström', ' O.; McDonald', ' R.; Uszkoreit', ' J. Cross-lingual Word Clusters for Direct Transfer of Linguistic Structure. HLT/NAACL', ' 2012; pp 477−487. ']\n",
      "25\n",
      "['Owoputi', ' O.; O’Connor', ' B.; Dyer', ' C.; Gimpel', ' K.; Schneider', ' N.; Smith', ' N. A. Improved Part-of-Speech Tagging for Online Conversational Text with Word Clusters. NAACL HLT 2013 (Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies)', ' Atlanta', ' Georgia', ' June 10−12', ' 2013; pp 380−390. ']\n",
      "26\n",
      "['Liang', ' P. Semi-Supervised Learning for Natural Language M.Sc. thesis', ' Massachusetts Institute of Technology', ' 2005. ']\n",
      "27\n",
      "['Bies', ' A.; Mott', ' J.; Warner', ' C. English News Text Treebank: Penn Treebank Revised LDC2015T13; Linguistic Data Consortium: Phila- delphia', ' 2015. ']\n",
      "28\n",
      "['Tateishi', ' Y.; Tsujii', \" J. Part-of-Speech Annotation of Biology Research Abstracts. LREC 2004 (Proceedings of the 4th International'\", \" 'J. Unsupervised Multilingual Sentence'\", \" 'the 48th Annual Meeting of'\", \" 'Conference on Language Resource and Evaluation)\", ' Lisbon', ' Portugal', ' May 26−28', ' 2004. ']\n",
      "29\n",
      "['Okazaki', ' N. CRFsuite: A Fast Implementation of Conditional Random Fields (CRFs). 2007; http://www.chokkan.org/software/ crfsuite/ (accessed October 3', ' 2016). ']\n",
      "30\n",
      "['Rocktaschel', ' T.; Weidlich', ' M.; Leser', ' U. ChemSpot: A Hybrid System for Chemical Named Entity Recognition. Bioinformatics 2012', ' 28', ' 1633−1640. ']\n",
      "31\n",
      "['Krallinger', ' M.; Leitner', ' F.; Rabal', ' O.; Vazquez', ' M.; Oyarzabal', ' J.; Valencia', ' A. CHEMDNER: The Drugs and Chemical Names Extraction Challenge. J. Cheminf. 2015', ' 7', ' S1. ']\n",
      "32\n",
      "['Krallinger', ' M.; Rabal', ' O.; Leitner', ' F.; Vazquez', ' M.; Salgado', ' D.; Lu', ' Z.; Leaman', ' R.; Lu', ' Y.; Ji', ' D.; Lowe', ' D. M.; Sayle', ' R. A.; Batista- Navarro', ' R. T.; Rak', ' R.; Huber', ' T.; Rocktäschel', ' T.; Matos', ' S.; Campos', ' D.; Tang', ' B.; Xu', ' H.; Munkhdalai', ' T.; Ryu', ' K. H.; Ramanan', ' S. V.; Nathan', ' S.; Žitnik', ' S.; Bajec', ' M.; Weber', ' L.; Irmer', ' M.; Akhondi', ' S. A.; Kors', ' J. A.; Xu', ' S.; An', ' X.; Sikdar', ' U. K.; Ekbal', ' A.; Yoshioka', ' M.; Dieb', ' T. M.; Choi', ' M.; Verspoor', ' K.; Khabsa', ' M.; Giles', ' C. L.; Liu', ' H.; Ravikumar', ' K. E.; Lamurias', ' A.; Couto', ' F. M.; Dai', ' H.-J.; Tsai', ' R. T.; Ata', ' C.; Can', ' T.; Usié', ' A.; Alves', ' R.; Segura-Bedmar', ' I.; Martínez', ' P.; Oyarzabal', ' J.; Valencia', ' A. The CHEMDNER Corpus of Chemicals and Drugs and Its Annotation Principles. J. Cheminf. 2015', ' 7', ' S2. ']\n",
      "33\n",
      "['Hettne', ' K. M.; Stierum', ' R. H.; Schuemie', ' M. J.; Hendriksen', ' P. J. M.; Schijvenaars', ' B. J. A.; Mulligen', ' E. M. v.; Kleinjans', ' J.; Kors', ' J. A. A Dictionary to Identify Small Molecules and Drugs in Free Text. Bioinformatics 2009', ' 25', ' 2983−2991. ']\n",
      "34\n",
      "['Schwartz', ' A. S.; Hearst', ' M. A. A Simple Algorithm for Identifying Abbreviation Definitions in Biomedical Text. Proc. Pacific Symp. 2003', ' 451. ']\n",
      "35\n",
      "['The manually-extracted gold standard output is available from http://chemdataextractor.org/evaluation along with the full text of the 50 source articles. ']\n",
      "36\n",
      "['Leaman', ' R.; Wei', ' C.-H.; Lu', ' Z. tmChem: A High Performance Approach for Chemical Named Entity Recognition and Normalization. J. Cheminf. 2015', ' 7', ' S3. ']\n",
      "37\n",
      "['(38) Lu', ' Y.; Ji', ' D.; Yao', ' X.; Wei', ' X.; Liang', ' X. CHEMDNER System with Mixed Conditional Random Fields and Multi-Scale Word Clustering. J. Cheminf. 2015', ' 7', \" S4.'\", \" ''\", \" 'DOI: 10.1021/acs.jcim.6b00207 J. Chem. Inf. Model. 2016\", ' 56', \" 1894−1904']\"]\n"
     ]
    }
   ],
   "source": [
    "for seq, ref in pdf.reference().items():\n",
    "    print(seq)\n",
    "    print(ref)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec7a089",
   "metadata": {},
   "source": [
    "## Pass multiple files at one time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e70f73ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5069a482",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single(file):\n",
    "    reader = Reader()\n",
    "    pdf = reader.read_file(file)\n",
    "    print(pdf.abstract())\n",
    "\n",
    "    \n",
    "def read_multiple(path):\n",
    "    for i in path:\n",
    "        read_single(i)\n",
    "        print('-------------------', '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2217ecc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading:  /Users/miao/Desktop/test/els/6.pdf\n",
      "*** Elsevier detected ***\n",
      "For policymakers, planners, urban design practitioners and city service decision-makers who endeavour to create policies and take decisions to improve the function of cities, developing an understanding of cities, and the particular city in question, is important. However, in the ever-increasing ﬁeld of urban measurement and analysis, the challenges cities face are frequently presumed: crime and fear of crime, social inequality, environmental degradation, economic deterioration and disjointed governance. Although it may be that many cities share similar problems, it is unwise to assume that cities share the same challenges, to the same degree or in the same combination. And yet, diagnosing the challenges a city faces is often overlooked in preference for improving the understanding of known challenges. To address this oversight, this study evidences the need to diagnose urban challenges, introduces a novel mixed-methods approach for doing so, applies (and critiques) the approach to the city of Birmingham, UK, and proposes a set of principles for the transferability of this new urban diagnostic methodology to other cities. The paper argues that applying a rigorous, explorative, diagnostic approach to ‘reading cities’ provides conﬁdence that all critical challenges have been identiﬁed and, crucially, identiﬁes how they are interdependent, both of which have implications for how policymakers and decision-makers address a particular city's combination of interlinked challenges.\n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/7.pdf\n",
      "*** Elsevier detected ***\n",
      "City bus drivers are facing increasingly stressful work situations. In urban areas, bus drivers are competing for limited road space with various vehicles in mixed trafﬁc conditions. This mixed trafﬁc ﬂow condition may not only cause trafﬁc congestion problems but also increase the driving fatigue of a city bus driver. In addition, the average number of elderly passengers are increasing. Constrained by their physical conditions, elderly passengers usually take more time to get on or off a bus and require a city bus driver’s special attention or help. An increase in elderly passengers using city buses may increase the bus driver’s stress and/or fatigue levels. This study developed a structural equation model to investi- gate the causal relationships between a vector of stress factors and city bus drivers’ fatigue levels from a risk management perspective. The empirical study results based on a ques- tionnaire survey indicated that mixed trafﬁc ﬂow conditions and the characteristics of elderly passengers are positively correlated with the levels of driving fatigue in city bus dri- vers. An increase in the number of motor scooters in a trafﬁc stream and/or elderly passen- gers on a bus will lead to higher levels of mental fatigue for a city bus driver. This study discussed the effects of several stressors on a city bus driver’s fatigue and provided sugges- tions for changes in policies to ensure the fatigue mitigation of city bus drivers.\n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/5.pdf\n",
      "*** Elsevier detected ***\n",
      "During  the  heating  season  in  the  “Three  North”  area  of  China,  the  wind  curtailment  has  become  a  serious  problem due to the lack of space for grid-connected wind power. Firstly, from the perspective of improving the  acceptance capacity of wind power curtailment, this paper establishes a model of hybrid energy storage. Then  considering the influence of the frequently changing electrodes of the regenerative electric boiler on its working  life, this paper introduces the optimization coefficient of electrodes, and the optimal operation strategy of hybrid  energy  storage  system  is  put  forward.  Finally,  based  on  the  actual  data  of  200  MW  wind  farm,  this  paper  compares and analyzes the advantages and disadvantages of different control methods. The results show that the  proposed method can further improve the power system’s ability to accept wind power, under the requirements  of meeting the heating demand and reducing the number of electrode adjustment of electric boilers.   \n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/4.pdf\n",
      "*** Elsevier detected ***\n",
      "In this paper we aim to analyze the status of investment and ﬁnancing of photovoltaic power generation in Cameroon, ﬁnd out the challenges it faces, and put forward solutions. Through in-depth analyses of the investment and ﬁnancing data of photovoltaic power generation from Cameroon, reference countries and the world during 2008e2019 and by drawing lessons from international experiences, we ﬁnd that Cameroon’s investment and ﬁnancing is far from meeting the needs of its photovoltaic power generation development. The causal analyses show that the root causes leading to insufﬁcient investment and ﬁnancing of photovoltaic power generation in Cameroon are the government behavior defects. On this basis, using the appropriate problem-oriented analysis method, we put forward policy recommendations to improve the investment and ﬁnancing situation of photovoltaic power generation in Cameroon. The basic conclusion of this paper is that the low investment scale, single ﬁnancing structure, violent in- vestment ﬂuctuation and ﬁnancing gap are the surface causes of slowing photovoltaic power generation in Cameroon, while the lack of consciousness about attracting international investment, the ambiguity of the application process for photovoltaic power generation projects, the lack of speciﬁc measures to stimulate photovoltaic power generation, and the backward national planning of photovoltaic power generation are the internal reasons delaying Cameroon’s photovoltaic power generation. This study not only beneﬁts Cameroon by being a guide for optimizing and promoting the development of photovoltaic power generation, but also has universal reference value for other similar research.\n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/1.pdf\n",
      "*** Elsevier detected ***\n",
      "Cities across the world are starting to recover space, previously devoted to cars, for other uses. The main purpose of this paper is to better understand the removal of space in urban settings and to provide some analytical results showing that it is possible to remove streets from a city without worsening trafﬁc excessively.\n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/3.pdf\n",
      "*** Elsevier detected ***\n",
      "Porcine pancreatic stem cells (pPSCs) can be induced to insulin-secreting cells and therefore considered the most promising seeding cells for curing human diabetes in future. However, insuﬃcient pPSCs number is one of the bottleneck problems before its clinical application. SerpinB1 is a serine protease inhibitor in neutrophils and can directly promote the proliferation of β cells. Whether SerpinB1 is involved in pPSC proliferation and diﬀer- entiation remains unknown. The eﬀects of SerpinB1 on pPSCs proliferation were measured by Cell Counting Kit- 8, 5-ethynyl-2′-deoxyuridine, qRT-PCR, western blot, and ﬂow cytometry assays. We found that pPSCs did not eﬃciently reach the S phase when SerpinB1 expression was knocked down with short hairpin RNA (sh- SerpinB1), the expression of Cyclin D1, CDK-2, and PCNA also decreased. Meanwhile, cell viability and pro- liferation ability were both declined. Further analyses showed that the expression level of phosphorylated STAT3/STAT3was downregulated, along with an upregulation of p53 and p21. We used a two-step induction method to induce pPSCs to insulin-secreting cells and found that SerpinB1 expression in insulin-secreting cells was higher than in pPSCs. Meanwhile, the protein expression level of phosphorylated STAT3/STAT3 was in- creased while p53 and p21 was decreased in induced insulin-secreting cells in comparison with control cells. The insulin-secreting cells derived from the sh-SerpinB1 cells secreted less insulin and showed poor sensitivity to high glucose than control group. However, the insulin-secreting cells derived from the ov-SerpinB1 cells has a quite contrary tendency. In conclusion, this study demonstrates that SerpinB1 promotes the proliferation of pPSCs through the STAT3 signaling pathway, and SerpinB1 is a key factor for maintaining the viability of pPSCs during the transition to insulin-secreting cells.\n",
      "------------------- \n",
      "\n",
      "Reading:  /Users/miao/Desktop/test/els/2.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Elsevier detected ***\n",
      "Cities are increasingly challenged to improve their competitiveness. Performance indicators stand as an important element to interpret the success of the policy regime adopted by the municipality. Cities with a set of superior economic, social and environmental indicators have the potential to present better living conditions for their inhabitants. In this context, the aim of this research is to analyze whether the in- dicators published by Brazilian cities are aligned with the approach of a smart or sustainable city. The research used a set of 3150 data points regarding the performance of these cities. It analyzed the per- formance of the 150 best cities, divided into three groups of interest identiﬁed as small cities, medium- sized cities and big cities, on a set of 21 indicators. The set of identiﬁed indicators shows the attention of the cities to socioeconomic and information and communication technologies issues, thus revealing that Brazilian city managers are more interested in positioning their cities as smart than sustainable. Analysis of the general indicators of the cities, supported by the number of inhabitants, indicated that big cities present superior performance in relation to medium-sized cities, and that the latter perform better in relation to the small cities. However, small cities in the individualized analysis of social indicators present a better-performing set.\n",
      "------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "read_multiple(glob.glob(r'/Users/miao/Desktop/test/els/*.pdf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c36e84",
   "metadata": {},
   "source": [
    "## Use PDFDataExtractor to perform chemistry related extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dcccb4",
   "metadata": {},
   "source": [
    "### You can use the flag \"chem=Ture\" to instruct the function to carry out chemistry related information extraction at the same time when extracting metadata, using ChemDataExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fecca4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_test = r'/Volumes/Backup/PDE_papers/articles/Elesvier/dssc/The-effect-of-molecular-structure-on-the-properties-of-quinox_2020_Dyes-and-.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4783bdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = Reader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02248767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading:  /Volumes/Backup/PDE_papers/articles/Elesvier/dssc/The-effect-of-molecular-structure-on-the-properties-of-quinox_2020_Dyes-and-.pdf\n",
      "*** Elsevier detected ***\n"
     ]
    }
   ],
   "source": [
    "pdf = reader.read_file(file_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df0c38",
   "metadata": {},
   "source": [
    "### Pass True to 'chem'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a84263e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = pdf.abstract(chem=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b4aa85",
   "metadata": {},
   "source": [
    "### Show records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1941ed13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'names': ['donor-π-bridge-acceptor-π']},\n",
       " {'names': ['quinoxaline']},\n",
       " {'names': ['deep red']}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.records.serialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f22f396",
   "metadata": {},
   "source": [
    "## Things to notice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158d1e36",
   "metadata": {},
   "source": [
    "### PDFDataExtractor uses ChemDataExtrator to perform all chemistry related extraction, for more detailed use cases, please refer to http://chemdataextractor.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931d6b09",
   "metadata": {},
   "source": [
    "## Known Issues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4456656f",
   "metadata": {},
   "source": [
    "In ACS\n",
    "* In ACS, a few journals have two section title styles existing at the same time, namely: numbered one and ■ one. This could confuse the title filtration function because two styles have largely different font sizes. But this won’t affect reference extraction\n",
    "* Reference extracted might not be in order\n",
    "* Parts of extracted reference could be missing\n",
    "\n",
    "In Elesvier\n",
    "* Potentially weak journal extraction leads to missing journal information\n",
    "* Unnumbered references can be messy\n",
    "\n",
    "In RSC\n",
    "* Title can be missing\n",
    "* Journal year, volume and page numbers can be missing in certain articles\n",
    "* Some section titles can be missed but reference section remains solid\n",
    "\n",
    "\n",
    "In Advanced Family\n",
    "* Reference entries can be mixed\n",
    "* Keywords can be found inside reference entries, roughly 1 in 20\n",
    "* Some authors place their bio at the very end, such words are not excluded from reference at the moment\n",
    "\n",
    "In CAEJ\n",
    "* Keywords can be incomplete\n",
    "\n",
    "In Angewandte\n",
    "* Keywords might not be in order"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ARIS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "975b18bc7dd0810880863e785de30ae921246198585ea656dcecbe7695289ba9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
